{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Loading H2O Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Get H2O Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'3.14.0.7'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2o.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Initalizing H2O cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:h2o:Key init.version_check is not a valid config key\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>9 hours 0 mins</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.14.0.7</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>24 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_avkashchauhan_1ocjkz</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.270 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>2.7.13 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         9 hours 0 mins\n",
       "H2O cluster version:        3.14.0.7\n",
       "H2O cluster version age:    24 days\n",
       "H2O cluster name:           H2O_from_python_avkashchauhan_1ocjkz\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.270 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         locked, healthy\n",
       "H2O connection url:         http://localhost:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             2.7.13 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Importing both training and test dataset into H2O cluster memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "#train_df = h2o.import_file(\"/Users/avkashchauhan/examples/prostate.csv\")\n",
    "\n",
    "train_df = h2o.import_file(\"https://raw.githubusercontent.com/Avkash/mldl/master/data/prostate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Understanding Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows:380\n",
      "Cols:9\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>       </th><th>ID           </th><th>CAPSULE       </th><th>AGE          </th><th>RACE          </th><th>DPROS        </th><th>DCAPS         </th><th>PSA          </th><th>VOL          </th><th>GLEASON      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>type   </td><td>int          </td><td>int           </td><td>int          </td><td>int           </td><td>int          </td><td>int           </td><td>real         </td><td>real         </td><td>int          </td></tr>\n",
       "<tr><td>mins   </td><td>1.0          </td><td>0.0           </td><td>43.0         </td><td>0.0           </td><td>1.0          </td><td>1.0           </td><td>0.3          </td><td>0.0          </td><td>0.0          </td></tr>\n",
       "<tr><td>mean   </td><td>190.5        </td><td>0.402631578947</td><td>66.0394736842</td><td>1.08684210526 </td><td>2.27105263158</td><td>1.10789473684 </td><td>15.4086315789</td><td>15.8129210526</td><td>6.38421052632</td></tr>\n",
       "<tr><td>maxs   </td><td>380.0        </td><td>1.0           </td><td>79.0         </td><td>2.0           </td><td>4.0          </td><td>2.0           </td><td>139.7        </td><td>97.6         </td><td>9.0          </td></tr>\n",
       "<tr><td>sigma  </td><td>109.840793879</td><td>0.491074338963</td><td>6.52707126917</td><td>0.308773258025</td><td>1.00010761815</td><td>0.310656449351</td><td>19.9975726686</td><td>18.3476199673</td><td>1.09195337443</td></tr>\n",
       "<tr><td>zeros  </td><td>0            </td><td>227           </td><td>0            </td><td>3             </td><td>0            </td><td>0             </td><td>0            </td><td>167          </td><td>2            </td></tr>\n",
       "<tr><td>missing</td><td>0            </td><td>0             </td><td>0            </td><td>0             </td><td>0            </td><td>0             </td><td>0            </td><td>0            </td><td>0            </td></tr>\n",
       "<tr><td>0      </td><td>1.0          </td><td>0.0           </td><td>65.0         </td><td>1.0           </td><td>2.0          </td><td>1.0           </td><td>1.4          </td><td>0.0          </td><td>6.0          </td></tr>\n",
       "<tr><td>1      </td><td>2.0          </td><td>0.0           </td><td>72.0         </td><td>1.0           </td><td>3.0          </td><td>2.0           </td><td>6.7          </td><td>0.0          </td><td>7.0          </td></tr>\n",
       "<tr><td>2      </td><td>3.0          </td><td>0.0           </td><td>70.0         </td><td>1.0           </td><td>1.0          </td><td>2.0           </td><td>4.9          </td><td>0.0          </td><td>6.0          </td></tr>\n",
       "<tr><td>3      </td><td>4.0          </td><td>0.0           </td><td>76.0         </td><td>2.0           </td><td>2.0          </td><td>1.0           </td><td>51.2         </td><td>20.0         </td><td>7.0          </td></tr>\n",
       "<tr><td>4      </td><td>5.0          </td><td>0.0           </td><td>69.0         </td><td>1.0           </td><td>1.0          </td><td>1.0           </td><td>12.3         </td><td>55.9         </td><td>6.0          </td></tr>\n",
       "<tr><td>5      </td><td>6.0          </td><td>1.0           </td><td>71.0         </td><td>1.0           </td><td>3.0          </td><td>2.0           </td><td>3.3          </td><td>0.0          </td><td>8.0          </td></tr>\n",
       "<tr><td>6      </td><td>7.0          </td><td>0.0           </td><td>68.0         </td><td>2.0           </td><td>4.0          </td><td>2.0           </td><td>31.9         </td><td>0.0          </td><td>7.0          </td></tr>\n",
       "<tr><td>7      </td><td>8.0          </td><td>0.0           </td><td>61.0         </td><td>2.0           </td><td>4.0          </td><td>2.0           </td><td>66.7         </td><td>27.2         </td><td>7.0          </td></tr>\n",
       "<tr><td>8      </td><td>9.0          </td><td>0.0           </td><td>69.0         </td><td>1.0           </td><td>1.0          </td><td>1.0           </td><td>3.9          </td><td>24.0         </td><td>7.0          </td></tr>\n",
       "<tr><td>9      </td><td>10.0         </td><td>0.0           </td><td>68.0         </td><td>2.0           </td><td>1.0          </td><td>2.0           </td><td>13.0         </td><td>0.0          </td><td>6.0          </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Training dataset - columns and rows details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Training  Dataframes - columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'ID', u'CAPSULE', u'AGE', u'RACE', u'DPROS', u'DCAPS', u'PSA', u'VOL', u'GLEASON']\n"
     ]
    }
   ],
   "source": [
    "print(train_df.col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Training  Dataframes - columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'ID', u'CAPSULE', u'AGE', u'RACE', u'DPROS', u'DCAPS', u'PSA', u'VOL', u'GLEASON']\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Training dataframes - columns by their type i.e. numeric, string, categorical(enum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns_by_type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Training  dataframes - columns type as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns_by_type(\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Training  dataframes - columns type as numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns_by_type(\"numeric\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Training  dataframes - columns type as categorical or enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns_by_type(\"categorical\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Settings response or target variable for supervised machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = \"CAPSULE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Understanding response variable values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[response].levels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Understanding response variable values as historgram in Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNRkQkqQmA0KS1PT/ATra/e/a6llVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111a5c610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[response].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Understanding response variable values as historgram in Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNRkQkqQmA0KS1PT/ATra/e/a6llVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1140ca310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[response].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Understanding response column as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h2o.frame.H2OFrame"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df[response])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Setting response column as factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df[response]= train_df[response].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Creating a list of all features we will use for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'ID', u'CAPSULE', u'AGE', u'RACE', u'DPROS', u'DCAPS', u'PSA', u'VOL', u'GLEASON']\n",
      "[u'ID', u'AGE', u'RACE', u'DPROS', u'DCAPS', u'PSA', u'VOL', u'GLEASON']\n"
     ]
    }
   ],
   "source": [
    "features = train_df.col_names\n",
    "print(features)\n",
    "features.remove(response)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Importing H2O H2OGeneralizedLinearEstimator to build GLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Building Gradient Boosting (GBM) - Regression model only with training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_model_with_training_only = H2OGradientBoostingEstimator()\n",
    "gbm_model_with_training_only.train(x= features, y = response, training_frame= train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_model_python_1510608322538_111\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0637863025683\n",
      "RMSE: 0.252559503025\n",
      "LogLoss: 0.244491796997\n",
      "Mean Per-Class Error: 0.0581900895454\n",
      "AUC: 0.98825256975\n",
      "Gini: 0.976505139501\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.369290229047: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>208.0</td>\n",
       "<td>19.0</td>\n",
       "<td>0.0837</td>\n",
       "<td> (19.0/227.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>5.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0327</td>\n",
       "<td> (5.0/153.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>213.0</td>\n",
       "<td>167.0</td>\n",
       "<td>0.0632</td>\n",
       "<td> (24.0/380.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      208  19   0.0837   (19.0/227.0)\n",
       "1      5    148  0.0327   (5.0/153.0)\n",
       "Total  213  167  0.0632   (24.0/380.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3692902</td>\n",
       "<td>0.925</td>\n",
       "<td>166.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3284870</td>\n",
       "<td>0.9554140</td>\n",
       "<td>172.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5709882</td>\n",
       "<td>0.9471366</td>\n",
       "<td>131.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4617671</td>\n",
       "<td>0.9368421</td>\n",
       "<td>150.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9740913</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.2716047</td>\n",
       "<td>1.0</td>\n",
       "<td>200.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9740913</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3692902</td>\n",
       "<td>0.8731243</td>\n",
       "<td>166.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4303894</td>\n",
       "<td>0.9295154</td>\n",
       "<td>158.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3692902</td>\n",
       "<td>0.9418099</td>\n",
       "<td>166.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.36929      0.925     166\n",
       "max f2                       0.328487     0.955414  172\n",
       "max f0point5                 0.570988     0.947137  131\n",
       "max accuracy                 0.461767     0.936842  150\n",
       "max precision                0.974091     1         0\n",
       "max recall                   0.271605     1         200\n",
       "max specificity              0.974091     1         0\n",
       "max absolute_mcc             0.36929      0.873124  166\n",
       "max min_per_class_accuracy   0.430389     0.929515  158\n",
       "max mean_per_class_accuracy  0.36929      0.94181   166"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 40.26 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0105263</td>\n",
       "<td>0.9656726</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0261438</td>\n",
       "<td>0.0261438</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0210526</td>\n",
       "<td>0.9589343</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0261438</td>\n",
       "<td>0.0522876</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0315789</td>\n",
       "<td>0.9507825</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0261438</td>\n",
       "<td>0.0784314</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0421053</td>\n",
       "<td>0.9422672</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0261438</td>\n",
       "<td>0.1045752</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.9301226</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0196078</td>\n",
       "<td>0.1241830</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.9044146</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1241830</td>\n",
       "<td>0.2483660</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.8446853</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1241830</td>\n",
       "<td>0.3725490</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.7961432</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1241830</td>\n",
       "<td>0.4967320</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.6723258</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2483660</td>\n",
       "<td>0.7450980</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.4587689</td>\n",
       "<td>1.6993464</td>\n",
       "<td>2.2875817</td>\n",
       "<td>0.6842105</td>\n",
       "<td>0.9210526</td>\n",
       "<td>0.1699346</td>\n",
       "<td>0.9150327</td>\n",
       "<td>69.9346405</td>\n",
       "<td>128.7581699</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.2941654</td>\n",
       "<td>0.7843137</td>\n",
       "<td>1.9869281</td>\n",
       "<td>0.3157895</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0784314</td>\n",
       "<td>0.9934641</td>\n",
       "<td>-21.5686275</td>\n",
       "<td>98.6928105</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.1936958</td>\n",
       "<td>0.0653595</td>\n",
       "<td>1.6666667</td>\n",
       "<td>0.0263158</td>\n",
       "<td>0.6710526</td>\n",
       "<td>0.0065359</td>\n",
       "<td>1.0</td>\n",
       "<td>-93.4640523</td>\n",
       "<td>66.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.1169011</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285714</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5751880</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0800475</td>\n",
       "<td>0.0</td>\n",
       "<td>1.25</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5032895</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0473553</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111111</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4473684</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0097484</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4026316</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0105263                   0.965673           2.48366    2.48366            1                1                           0.0261438       0.0261438                  148.366   148.366\n",
       "    2        0.0210526                   0.958934           2.48366    2.48366            1                1                           0.0261438       0.0522876                  148.366   148.366\n",
       "    3        0.0315789                   0.950783           2.48366    2.48366            1                1                           0.0261438       0.0784314                  148.366   148.366\n",
       "    4        0.0421053                   0.942267           2.48366    2.48366            1                1                           0.0261438       0.104575                   148.366   148.366\n",
       "    5        0.05                        0.930123           2.48366    2.48366            1                1                           0.0196078       0.124183                   148.366   148.366\n",
       "    6        0.1                         0.904415           2.48366    2.48366            1                1                           0.124183        0.248366                   148.366   148.366\n",
       "    7        0.15                        0.844685           2.48366    2.48366            1                1                           0.124183        0.372549                   148.366   148.366\n",
       "    8        0.2                         0.796143           2.48366    2.48366            1                1                           0.124183        0.496732                   148.366   148.366\n",
       "    9        0.3                         0.672326           2.48366    2.48366            1                1                           0.248366        0.745098                   148.366   148.366\n",
       "    10       0.4                         0.458769           1.69935    2.28758            0.684211         0.921053                    0.169935        0.915033                   69.9346   128.758\n",
       "    11       0.5                         0.294165           0.784314   1.98693            0.315789         0.8                         0.0784314       0.993464                   -21.5686  98.6928\n",
       "    12       0.6                         0.193696           0.0653595  1.66667            0.0263158        0.671053                    0.00653595      1                          -93.4641  66.6667\n",
       "    13       0.7                         0.116901           0          1.42857            0                0.575188                    0               1                          -100      42.8571\n",
       "    14       0.8                         0.0800475          0          1.25               0                0.503289                    0               1                          -100      25\n",
       "    15       0.9                         0.0473553          0          1.11111            0                0.447368                    0               1                          -100      11.1111\n",
       "    16       1                           0.00974841         0          1                  0                0.402632                    0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:26:45</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4904278</td>\n",
       "<td>0.6740643</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5973684</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:26:45</td>\n",
       "<td> 0.010 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4686191</td>\n",
       "<td>0.6307225</td>\n",
       "<td>0.8893064</td>\n",
       "<td>2.4836601</td>\n",
       "<td>0.2052632</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:26:45</td>\n",
       "<td> 0.019 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.4511855</td>\n",
       "<td>0.5972755</td>\n",
       "<td>0.8968789</td>\n",
       "<td>2.4836601</td>\n",
       "<td>0.1868421</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:26:45</td>\n",
       "<td> 0.032 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.4364517</td>\n",
       "<td>0.5695314</td>\n",
       "<td>0.8989807</td>\n",
       "<td>2.4836601</td>\n",
       "<td>0.1815789</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:26:45</td>\n",
       "<td> 0.039 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.4235059</td>\n",
       "<td>0.5454486</td>\n",
       "<td>0.9031845</td>\n",
       "<td>2.4836601</td>\n",
       "<td>0.1684211</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:26:45</td>\n",
       "<td> 0.292 sec</td>\n",
       "<td>46.0</td>\n",
       "<td>0.2607981</td>\n",
       "<td>0.2566517</td>\n",
       "<td>0.9857764</td>\n",
       "<td>2.4836601</td>\n",
       "<td>0.0631579</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:26:45</td>\n",
       "<td> 0.299 sec</td>\n",
       "<td>47.0</td>\n",
       "<td>0.2579166</td>\n",
       "<td>0.2523916</td>\n",
       "<td>0.9866690</td>\n",
       "<td>2.4836601</td>\n",
       "<td>0.0657895</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:26:45</td>\n",
       "<td> 0.305 sec</td>\n",
       "<td>48.0</td>\n",
       "<td>0.2570579</td>\n",
       "<td>0.2508900</td>\n",
       "<td>0.9866978</td>\n",
       "<td>2.4836601</td>\n",
       "<td>0.0631579</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:26:45</td>\n",
       "<td> 0.312 sec</td>\n",
       "<td>49.0</td>\n",
       "<td>0.2535220</td>\n",
       "<td>0.2459155</td>\n",
       "<td>0.9880510</td>\n",
       "<td>2.4836601</td>\n",
       "<td>0.0631579</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:26:45</td>\n",
       "<td> 0.318 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.2525595</td>\n",
       "<td>0.2444918</td>\n",
       "<td>0.9882526</td>\n",
       "<td>2.4836601</td>\n",
       "<td>0.0631579</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_lift    training_classification_error\n",
       "---  -------------------  ----------  -----------------  ---------------  ------------------  --------------  ---------------  -------------------------------\n",
       "     2017-11-13 22:26:45  0.000 sec   0.0                0.490427762858   0.674064263401      0.5             1.0              0.597368421053\n",
       "     2017-11-13 22:26:45  0.010 sec   1.0                0.468619074637   0.630722536895      0.889306383346  2.48366013072    0.205263157895\n",
       "     2017-11-13 22:26:45  0.019 sec   2.0                0.451185464277   0.597275528716      0.896878869022  2.48366013072    0.186842105263\n",
       "     2017-11-13 22:26:45  0.032 sec   3.0                0.436451698786   0.569531355681      0.89898073767   2.48366013072    0.181578947368\n",
       "     2017-11-13 22:26:45  0.039 sec   4.0                0.42350586729    0.545448639588      0.903184474965  2.48366013072    0.168421052632\n",
       "---  ---                  ---         ---                ---              ---                 ---             ---              ---\n",
       "     2017-11-13 22:26:45  0.292 sec   46.0               0.260798063771   0.25665171288       0.985776395727  2.48366013072    0.0631578947368\n",
       "     2017-11-13 22:26:45  0.299 sec   47.0               0.257916552548   0.252391619428      0.986668970084  2.48366013072    0.0657894736842\n",
       "     2017-11-13 22:26:45  0.305 sec   48.0               0.257057914235   0.250889978828      0.986697762806  2.48366013072    0.0631578947368\n",
       "     2017-11-13 22:26:45  0.312 sec   49.0               0.253522031578   0.245915459067      0.988051020702  2.48366013072    0.0631578947368\n",
       "     2017-11-13 22:26:45  0.318 sec   50.0               0.252559503025   0.244491796997      0.98825256975   2.48366013072    0.0631578947368"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>GLEASON</td>\n",
       "<td>110.3258133</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3229987</td></tr>\n",
       "<tr><td>ID</td>\n",
       "<td>58.6968040</td>\n",
       "<td>0.5320315</td>\n",
       "<td>0.1718455</td></tr>\n",
       "<tr><td>PSA</td>\n",
       "<td>57.7674637</td>\n",
       "<td>0.5236079</td>\n",
       "<td>0.1691247</td></tr>\n",
       "<tr><td>VOL</td>\n",
       "<td>40.0885315</td>\n",
       "<td>0.3633649</td>\n",
       "<td>0.1173664</td></tr>\n",
       "<tr><td>DPROS</td>\n",
       "<td>34.9556313</td>\n",
       "<td>0.3168400</td>\n",
       "<td>0.1023389</td></tr>\n",
       "<tr><td>AGE</td>\n",
       "<td>31.4995918</td>\n",
       "<td>0.2855142</td>\n",
       "<td>0.0922207</td></tr>\n",
       "<tr><td>DCAPS</td>\n",
       "<td>7.1565890</td>\n",
       "<td>0.0648678</td>\n",
       "<td>0.0209522</td></tr>\n",
       "<tr><td>RACE</td>\n",
       "<td>1.0769546</td>\n",
       "<td>0.0097616</td>\n",
       "<td>0.0031530</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  ------------\n",
       "GLEASON     110.326                1                    0.322999\n",
       "ID          58.6968                0.532031             0.171845\n",
       "PSA         57.7675                0.523608             0.169125\n",
       "VOL         40.0885                0.363365             0.117366\n",
       "DPROS       34.9556                0.31684              0.102339\n",
       "AGE         31.4996                0.285514             0.0922207\n",
       "DCAPS       7.15659                0.0648678            0.0209522\n",
       "RACE        1.07695                0.00976158           0.00315298"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model_with_training_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#:Building Gradient Boosting (GBM) -  Regression model with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_model_with_training_and_cv = H2OGradientBoostingEstimator(nfolds=5)\n",
    "gbm_model_with_training_and_cv.train(x = features, y = response, training_frame=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  GBM_model_python_1510608322538_214\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0637863025683\n",
      "RMSE: 0.252559503025\n",
      "LogLoss: 0.244491796997\n",
      "Mean Per-Class Error: 0.0581900895454\n",
      "AUC: 0.98825256975\n",
      "Gini: 0.976505139501\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.369290229047: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>208.0</td>\n",
       "<td>19.0</td>\n",
       "<td>0.0837</td>\n",
       "<td> (19.0/227.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>5.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0327</td>\n",
       "<td> (5.0/153.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>213.0</td>\n",
       "<td>167.0</td>\n",
       "<td>0.0632</td>\n",
       "<td> (24.0/380.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      208  19   0.0837   (19.0/227.0)\n",
       "1      5    148  0.0327   (5.0/153.0)\n",
       "Total  213  167  0.0632   (24.0/380.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3692902</td>\n",
       "<td>0.925</td>\n",
       "<td>166.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3284870</td>\n",
       "<td>0.9554140</td>\n",
       "<td>172.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5709882</td>\n",
       "<td>0.9471366</td>\n",
       "<td>131.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4617671</td>\n",
       "<td>0.9368421</td>\n",
       "<td>150.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9740913</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.2716047</td>\n",
       "<td>1.0</td>\n",
       "<td>200.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9740913</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3692902</td>\n",
       "<td>0.8731243</td>\n",
       "<td>166.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4303894</td>\n",
       "<td>0.9295154</td>\n",
       "<td>158.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3692902</td>\n",
       "<td>0.9418099</td>\n",
       "<td>166.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.36929      0.925     166\n",
       "max f2                       0.328487     0.955414  172\n",
       "max f0point5                 0.570988     0.947137  131\n",
       "max accuracy                 0.461767     0.936842  150\n",
       "max precision                0.974091     1         0\n",
       "max recall                   0.271605     1         200\n",
       "max specificity              0.974091     1         0\n",
       "max absolute_mcc             0.36929      0.873124  166\n",
       "max min_per_class_accuracy   0.430389     0.929515  158\n",
       "max mean_per_class_accuracy  0.36929      0.94181   166"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 40.26 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0105263</td>\n",
       "<td>0.9656726</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0261438</td>\n",
       "<td>0.0261438</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0210526</td>\n",
       "<td>0.9589343</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0261438</td>\n",
       "<td>0.0522876</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0315789</td>\n",
       "<td>0.9507825</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0261438</td>\n",
       "<td>0.0784314</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0421053</td>\n",
       "<td>0.9422672</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0261438</td>\n",
       "<td>0.1045752</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.9301226</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0196078</td>\n",
       "<td>0.1241830</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.9044146</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1241830</td>\n",
       "<td>0.2483660</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.8446853</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1241830</td>\n",
       "<td>0.3725490</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.7961432</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1241830</td>\n",
       "<td>0.4967320</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.6723258</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2483660</td>\n",
       "<td>0.7450980</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.4587689</td>\n",
       "<td>1.6993464</td>\n",
       "<td>2.2875817</td>\n",
       "<td>0.6842105</td>\n",
       "<td>0.9210526</td>\n",
       "<td>0.1699346</td>\n",
       "<td>0.9150327</td>\n",
       "<td>69.9346405</td>\n",
       "<td>128.7581699</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.2941654</td>\n",
       "<td>0.7843137</td>\n",
       "<td>1.9869281</td>\n",
       "<td>0.3157895</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0784314</td>\n",
       "<td>0.9934641</td>\n",
       "<td>-21.5686275</td>\n",
       "<td>98.6928105</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.1936958</td>\n",
       "<td>0.0653595</td>\n",
       "<td>1.6666667</td>\n",
       "<td>0.0263158</td>\n",
       "<td>0.6710526</td>\n",
       "<td>0.0065359</td>\n",
       "<td>1.0</td>\n",
       "<td>-93.4640523</td>\n",
       "<td>66.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.1169011</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285714</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5751880</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0800475</td>\n",
       "<td>0.0</td>\n",
       "<td>1.25</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5032895</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0473553</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111111</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4473684</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0097484</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4026316</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0105263                   0.965673           2.48366    2.48366            1                1                           0.0261438       0.0261438                  148.366   148.366\n",
       "    2        0.0210526                   0.958934           2.48366    2.48366            1                1                           0.0261438       0.0522876                  148.366   148.366\n",
       "    3        0.0315789                   0.950783           2.48366    2.48366            1                1                           0.0261438       0.0784314                  148.366   148.366\n",
       "    4        0.0421053                   0.942267           2.48366    2.48366            1                1                           0.0261438       0.104575                   148.366   148.366\n",
       "    5        0.05                        0.930123           2.48366    2.48366            1                1                           0.0196078       0.124183                   148.366   148.366\n",
       "    6        0.1                         0.904415           2.48366    2.48366            1                1                           0.124183        0.248366                   148.366   148.366\n",
       "    7        0.15                        0.844685           2.48366    2.48366            1                1                           0.124183        0.372549                   148.366   148.366\n",
       "    8        0.2                         0.796143           2.48366    2.48366            1                1                           0.124183        0.496732                   148.366   148.366\n",
       "    9        0.3                         0.672326           2.48366    2.48366            1                1                           0.248366        0.745098                   148.366   148.366\n",
       "    10       0.4                         0.458769           1.69935    2.28758            0.684211         0.921053                    0.169935        0.915033                   69.9346   128.758\n",
       "    11       0.5                         0.294165           0.784314   1.98693            0.315789         0.8                         0.0784314       0.993464                   -21.5686  98.6928\n",
       "    12       0.6                         0.193696           0.0653595  1.66667            0.0263158        0.671053                    0.00653595      1                          -93.4641  66.6667\n",
       "    13       0.7                         0.116901           0          1.42857            0                0.575188                    0               1                          -100      42.8571\n",
       "    14       0.8                         0.0800475          0          1.25               0                0.503289                    0               1                          -100      25\n",
       "    15       0.9                         0.0473553          0          1.11111            0                0.447368                    0               1                          -100      11.1111\n",
       "    16       1                           0.00974841         0          1                  0                0.402632                    0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.193449479928\n",
      "RMSE: 0.439828921204\n",
      "LogLoss: 0.583803714321\n",
      "Mean Per-Class Error: 0.2749560911\n",
      "AUC: 0.771385793671\n",
      "Gini: 0.542771587343\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.227900946183: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>131.0</td>\n",
       "<td>96.0</td>\n",
       "<td>0.4229</td>\n",
       "<td> (96.0/227.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>21.0</td>\n",
       "<td>132.0</td>\n",
       "<td>0.1373</td>\n",
       "<td> (21.0/153.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>152.0</td>\n",
       "<td>228.0</td>\n",
       "<td>0.3079</td>\n",
       "<td> (117.0/380.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -------------\n",
       "0      131  96   0.4229   (96.0/227.0)\n",
       "1      21   132  0.1373   (21.0/153.0)\n",
       "Total  152  228  0.3079   (117.0/380.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2279009</td>\n",
       "<td>0.6929134</td>\n",
       "<td>227.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1465578</td>\n",
       "<td>0.7931034</td>\n",
       "<td>257.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5129327</td>\n",
       "<td>0.6620690</td>\n",
       "<td>142.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5129327</td>\n",
       "<td>0.7263158</td>\n",
       "<td>142.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9811968</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0154869</td>\n",
       "<td>1.0</td>\n",
       "<td>375.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9811968</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3624449</td>\n",
       "<td>0.4426745</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3805118</td>\n",
       "<td>0.7224670</td>\n",
       "<td>173.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3624449</td>\n",
       "<td>0.7250439</td>\n",
       "<td>175.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.227901     0.692913  227\n",
       "max f2                       0.146558     0.793103  257\n",
       "max f0point5                 0.512933     0.662069  142\n",
       "max accuracy                 0.512933     0.726316  142\n",
       "max precision                0.981197     1         0\n",
       "max recall                   0.0154869    1         375\n",
       "max specificity              0.981197     1         0\n",
       "max absolute_mcc             0.362445     0.442674  175\n",
       "max min_per_class_accuracy   0.380512     0.722467  173\n",
       "max mean_per_class_accuracy  0.362445     0.725044  175"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 40.26 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0105263</td>\n",
       "<td>0.9662284</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0261438</td>\n",
       "<td>0.0261438</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0210526</td>\n",
       "<td>0.9480133</td>\n",
       "<td>1.8627451</td>\n",
       "<td>2.1732026</td>\n",
       "<td>0.75</td>\n",
       "<td>0.875</td>\n",
       "<td>0.0196078</td>\n",
       "<td>0.0457516</td>\n",
       "<td>86.2745098</td>\n",
       "<td>117.3202614</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0315789</td>\n",
       "<td>0.9397978</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.2766885</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9166667</td>\n",
       "<td>0.0261438</td>\n",
       "<td>0.0718954</td>\n",
       "<td>148.3660131</td>\n",
       "<td>127.6688453</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0421053</td>\n",
       "<td>0.9337589</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.3284314</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9375</td>\n",
       "<td>0.0261438</td>\n",
       "<td>0.0980392</td>\n",
       "<td>148.3660131</td>\n",
       "<td>132.8431373</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.9183419</td>\n",
       "<td>1.6557734</td>\n",
       "<td>2.2222222</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.8947368</td>\n",
       "<td>0.0130719</td>\n",
       "<td>0.1111111</td>\n",
       "<td>65.5773420</td>\n",
       "<td>122.2222222</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.8456098</td>\n",
       "<td>1.8300654</td>\n",
       "<td>2.0261438</td>\n",
       "<td>0.7368421</td>\n",
       "<td>0.8157895</td>\n",
       "<td>0.0915033</td>\n",
       "<td>0.2026144</td>\n",
       "<td>83.0065359</td>\n",
       "<td>102.6143791</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.7985739</td>\n",
       "<td>1.4379085</td>\n",
       "<td>1.8300654</td>\n",
       "<td>0.5789474</td>\n",
       "<td>0.7368421</td>\n",
       "<td>0.0718954</td>\n",
       "<td>0.2745098</td>\n",
       "<td>43.7908497</td>\n",
       "<td>83.0065359</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.6954812</td>\n",
       "<td>1.3071895</td>\n",
       "<td>1.6993464</td>\n",
       "<td>0.5263158</td>\n",
       "<td>0.6842105</td>\n",
       "<td>0.0653595</td>\n",
       "<td>0.3398693</td>\n",
       "<td>30.7189542</td>\n",
       "<td>69.9346405</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.5981705</td>\n",
       "<td>1.5686275</td>\n",
       "<td>1.6557734</td>\n",
       "<td>0.6315789</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.1568627</td>\n",
       "<td>0.4967320</td>\n",
       "<td>56.8627451</td>\n",
       "<td>65.5773420</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.4783089</td>\n",
       "<td>1.5686275</td>\n",
       "<td>1.6339869</td>\n",
       "<td>0.6315789</td>\n",
       "<td>0.6578947</td>\n",
       "<td>0.1568627</td>\n",
       "<td>0.6535948</td>\n",
       "<td>56.8627451</td>\n",
       "<td>63.3986928</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.3313758</td>\n",
       "<td>0.9803922</td>\n",
       "<td>1.5032680</td>\n",
       "<td>0.3947368</td>\n",
       "<td>0.6052632</td>\n",
       "<td>0.0980392</td>\n",
       "<td>0.7516340</td>\n",
       "<td>-1.9607843</td>\n",
       "<td>50.3267974</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.2271270</td>\n",
       "<td>1.1111111</td>\n",
       "<td>1.4379085</td>\n",
       "<td>0.4473684</td>\n",
       "<td>0.5789474</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.8627451</td>\n",
       "<td>11.1111111</td>\n",
       "<td>43.7908497</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.1341964</td>\n",
       "<td>0.3921569</td>\n",
       "<td>1.2885154</td>\n",
       "<td>0.1578947</td>\n",
       "<td>0.5187970</td>\n",
       "<td>0.0392157</td>\n",
       "<td>0.9019608</td>\n",
       "<td>-60.7843137</td>\n",
       "<td>28.8515406</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0886707</td>\n",
       "<td>0.3267974</td>\n",
       "<td>1.1683007</td>\n",
       "<td>0.1315789</td>\n",
       "<td>0.4703947</td>\n",
       "<td>0.0326797</td>\n",
       "<td>0.9346405</td>\n",
       "<td>-67.3202614</td>\n",
       "<td>16.8300654</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0480988</td>\n",
       "<td>0.3267974</td>\n",
       "<td>1.0748003</td>\n",
       "<td>0.1315789</td>\n",
       "<td>0.4327485</td>\n",
       "<td>0.0326797</td>\n",
       "<td>0.9673203</td>\n",
       "<td>-67.3202614</td>\n",
       "<td>7.4800290</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0108880</td>\n",
       "<td>0.3267974</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1315789</td>\n",
       "<td>0.4026316</td>\n",
       "<td>0.0326797</td>\n",
       "<td>1.0</td>\n",
       "<td>-67.3202614</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0105263                   0.966228           2.48366   2.48366            1                1                           0.0261438       0.0261438                  148.366   148.366\n",
       "    2        0.0210526                   0.948013           1.86275   2.1732             0.75             0.875                       0.0196078       0.0457516                  86.2745   117.32\n",
       "    3        0.0315789                   0.939798           2.48366   2.27669            1                0.916667                    0.0261438       0.0718954                  148.366   127.669\n",
       "    4        0.0421053                   0.933759           2.48366   2.32843            1                0.9375                      0.0261438       0.0980392                  148.366   132.843\n",
       "    5        0.05                        0.918342           1.65577   2.22222            0.666667         0.894737                    0.0130719       0.111111                   65.5773   122.222\n",
       "    6        0.1                         0.84561            1.83007   2.02614            0.736842         0.815789                    0.0915033       0.202614                   83.0065   102.614\n",
       "    7        0.15                        0.798574           1.43791   1.83007            0.578947         0.736842                    0.0718954       0.27451                    43.7908   83.0065\n",
       "    8        0.2                         0.695481           1.30719   1.69935            0.526316         0.684211                    0.0653595       0.339869                   30.719    69.9346\n",
       "    9        0.3                         0.59817            1.56863   1.65577            0.631579         0.666667                    0.156863        0.496732                   56.8627   65.5773\n",
       "    10       0.4                         0.478309           1.56863   1.63399            0.631579         0.657895                    0.156863        0.653595                   56.8627   63.3987\n",
       "    11       0.5                         0.331376           0.980392  1.50327            0.394737         0.605263                    0.0980392       0.751634                   -1.96078  50.3268\n",
       "    12       0.6                         0.227127           1.11111   1.43791            0.447368         0.578947                    0.111111        0.862745                   11.1111   43.7908\n",
       "    13       0.7                         0.134196           0.392157  1.28852            0.157895         0.518797                    0.0392157       0.901961                   -60.7843  28.8515\n",
       "    14       0.8                         0.0886707          0.326797  1.1683             0.131579         0.470395                    0.0326797       0.934641                   -67.3203  16.8301\n",
       "    15       0.9                         0.0480988          0.326797  1.0748             0.131579         0.432749                    0.0326797       0.96732                    -67.3203  7.48003\n",
       "    16       1                           0.010888           0.326797  1                  0.131579         0.402632                    0.0326797       1                          -67.3203  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.7287913</td>\n",
       "<td>0.0403975</td>\n",
       "<td>0.71875</td>\n",
       "<td>0.7228916</td>\n",
       "<td>0.6375</td>\n",
       "<td>0.8148148</td>\n",
       "<td>0.75</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.7700940</td>\n",
       "<td>0.0343016</td>\n",
       "<td>0.7761486</td>\n",
       "<td>0.7654762</td>\n",
       "<td>0.74</td>\n",
       "<td>0.8565051</td>\n",
       "<td>0.7123404</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.2712087</td>\n",
       "<td>0.0403975</td>\n",
       "<td>0.28125</td>\n",
       "<td>0.2771084</td>\n",
       "<td>0.3625</td>\n",
       "<td>0.1851852</td>\n",
       "<td>0.25</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>20.6</td>\n",
       "<td>3.481379</td>\n",
       "<td>18.0</td>\n",
       "<td>23.0</td>\n",
       "<td>29.0</td>\n",
       "<td>15.0</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.6605104</td>\n",
       "<td>0.0457309</td>\n",
       "<td>0.698324</td>\n",
       "<td>0.6595745</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.75</td>\n",
       "<td>0.6390978</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.7086272</td>\n",
       "<td>0.0374964</td>\n",
       "<td>0.7352941</td>\n",
       "<td>0.7294118</td>\n",
       "<td>0.6419753</td>\n",
       "<td>0.7826087</td>\n",
       "<td>0.6538461</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.7679788</td>\n",
       "<td>0.0383096</td>\n",
       "<td>0.7763975</td>\n",
       "<td>0.8157895</td>\n",
       "<td>0.7602339</td>\n",
       "<td>0.8181818</td>\n",
       "<td>0.6692913</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.5027723</td>\n",
       "<td>0.1947544</td>\n",
       "<td>2.064516</td>\n",
       "<td>2.3714285</td>\n",
       "<td>2.6666667</td>\n",
       "<td>2.53125</td>\n",
       "<td>2.88</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.5868385</td>\n",
       "<td>0.0469577</td>\n",
       "<td>0.6350344</td>\n",
       "<td>0.6178322</td>\n",
       "<td>0.5942904</td>\n",
       "<td>0.4570368</td>\n",
       "<td>0.6299987</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.3567103</td>\n",
       "<td>0.0683767</td>\n",
       "<td>0.3636364</td>\n",
       "<td>0.3958333</td>\n",
       "<td>0.5</td>\n",
       "<td>0.2040816</td>\n",
       "<td>0.32</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.4797853</td>\n",
       "<td>0.0597850</td>\n",
       "<td>0.4481028</td>\n",
       "<td>0.4943143</td>\n",
       "<td>0.3692606</td>\n",
       "<td>0.6277702</td>\n",
       "<td>0.4594786</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.7406265</td>\n",
       "<td>0.0316125</td>\n",
       "<td>0.7214076</td>\n",
       "<td>0.7449405</td>\n",
       "<td>0.6833333</td>\n",
       "<td>0.8198342</td>\n",
       "<td>0.733617</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.2593735</td>\n",
       "<td>0.0316125</td>\n",
       "<td>0.2785924</td>\n",
       "<td>0.2550595</td>\n",
       "<td>0.3166667</td>\n",
       "<td>0.1801658</td>\n",
       "<td>0.266383</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.1942187</td>\n",
       "<td>0.0162859</td>\n",
       "<td>0.2053715</td>\n",
       "<td>0.2031166</td>\n",
       "<td>0.2082852</td>\n",
       "<td>0.1482733</td>\n",
       "<td>0.2060471</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.6329678</td>\n",
       "<td>0.0515126</td>\n",
       "<td>0.6756757</td>\n",
       "<td>0.62</td>\n",
       "<td>0.5098040</td>\n",
       "<td>0.7297297</td>\n",
       "<td>0.6296296</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.1853289</td>\n",
       "<td>0.0724643</td>\n",
       "<td>0.1777110</td>\n",
       "<td>0.1671011</td>\n",
       "<td>0.1113163</td>\n",
       "<td>0.3795783</td>\n",
       "<td>0.0909377</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.8165165</td>\n",
       "<td>0.0517524</td>\n",
       "<td>0.8064516</td>\n",
       "<td>0.8857143</td>\n",
       "<td>0.8666667</td>\n",
       "<td>0.84375</td>\n",
       "<td>0.68</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.4398467</td>\n",
       "<td>0.0194116</td>\n",
       "<td>0.4531793</td>\n",
       "<td>0.4506846</td>\n",
       "<td>0.4563828</td>\n",
       "<td>0.3850627</td>\n",
       "<td>0.4539241</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.6647366</td>\n",
       "<td>0.0798913</td>\n",
       "<td>0.6363636</td>\n",
       "<td>0.6041667</td>\n",
       "<td>0.5</td>\n",
       "<td>0.7959183</td>\n",
       "<td>0.7872341</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean      sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  --------  ---------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.728791  0.0403975  0.71875       0.722892      0.6375        0.814815      0.75\n",
       "auc                      0.770094  0.0343016  0.776149      0.765476      0.74          0.856505      0.71234\n",
       "err                      0.271209  0.0403975  0.28125       0.277108      0.3625        0.185185      0.25\n",
       "err_count                20.6      3.48138    18            23            29            15            18\n",
       "f0point5                 0.66051   0.0457309  0.698324      0.659574      0.555556      0.75          0.639098\n",
       "f1                       0.708627  0.0374964  0.735294      0.729412      0.641975      0.782609      0.653846\n",
       "f2                       0.767979  0.0383096  0.776397      0.815789      0.760234      0.818182      0.669291\n",
       "lift_top_group           2.50277   0.194754   2.06452       2.37143       2.66667       2.53125       2.88\n",
       "logloss                  0.586839  0.0469577  0.635034      0.617832      0.59429       0.457037      0.629999\n",
       "max_per_class_error      0.35671   0.0683767  0.363636      0.395833      0.5           0.204082      0.32\n",
       "mcc                      0.479785  0.059785   0.448103      0.494314      0.369261      0.62777       0.459479\n",
       "mean_per_class_accuracy  0.740626  0.0316125  0.721408      0.74494       0.683333      0.819834      0.733617\n",
       "mean_per_class_error     0.259373  0.0316125  0.278592      0.255059      0.316667      0.180166      0.266383\n",
       "mse                      0.194219  0.0162859  0.205372      0.203117      0.208285      0.148273      0.206047\n",
       "precision                0.632968  0.0515126  0.675676      0.62          0.509804      0.72973       0.62963\n",
       "r2                       0.185329  0.0724643  0.177711      0.167101      0.111316      0.379578      0.0909377\n",
       "recall                   0.816516  0.0517524  0.806452      0.885714      0.866667      0.84375       0.68\n",
       "rmse                     0.439847  0.0194116  0.453179      0.450685      0.456383      0.385063      0.453924\n",
       "specificity              0.664737  0.0798913  0.636364      0.604167      0.5           0.795918      0.787234"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:26:47</td>\n",
       "<td> 0.694 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4904278</td>\n",
       "<td>0.6740643</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5973684</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:26:47</td>\n",
       "<td> 0.698 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4686191</td>\n",
       "<td>0.6307225</td>\n",
       "<td>0.8893064</td>\n",
       "<td>2.4836601</td>\n",
       "<td>0.2052632</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:26:47</td>\n",
       "<td> 0.702 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.4511855</td>\n",
       "<td>0.5972755</td>\n",
       "<td>0.8968789</td>\n",
       "<td>2.4836601</td>\n",
       "<td>0.1868421</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:26:47</td>\n",
       "<td> 0.705 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.4364517</td>\n",
       "<td>0.5695314</td>\n",
       "<td>0.8989807</td>\n",
       "<td>2.4836601</td>\n",
       "<td>0.1815789</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:26:47</td>\n",
       "<td> 0.708 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.4235059</td>\n",
       "<td>0.5454486</td>\n",
       "<td>0.9031845</td>\n",
       "<td>2.4836601</td>\n",
       "<td>0.1684211</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:26:47</td>\n",
       "<td> 0.929 sec</td>\n",
       "<td>46.0</td>\n",
       "<td>0.2607981</td>\n",
       "<td>0.2566517</td>\n",
       "<td>0.9857764</td>\n",
       "<td>2.4836601</td>\n",
       "<td>0.0631579</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:26:47</td>\n",
       "<td> 0.934 sec</td>\n",
       "<td>47.0</td>\n",
       "<td>0.2579166</td>\n",
       "<td>0.2523916</td>\n",
       "<td>0.9866690</td>\n",
       "<td>2.4836601</td>\n",
       "<td>0.0657895</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:26:47</td>\n",
       "<td> 0.940 sec</td>\n",
       "<td>48.0</td>\n",
       "<td>0.2570579</td>\n",
       "<td>0.2508900</td>\n",
       "<td>0.9866978</td>\n",
       "<td>2.4836601</td>\n",
       "<td>0.0631579</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:26:47</td>\n",
       "<td> 0.946 sec</td>\n",
       "<td>49.0</td>\n",
       "<td>0.2535220</td>\n",
       "<td>0.2459155</td>\n",
       "<td>0.9880510</td>\n",
       "<td>2.4836601</td>\n",
       "<td>0.0631579</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:26:47</td>\n",
       "<td> 0.951 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.2525595</td>\n",
       "<td>0.2444918</td>\n",
       "<td>0.9882526</td>\n",
       "<td>2.4836601</td>\n",
       "<td>0.0631579</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_lift    training_classification_error\n",
       "---  -------------------  ----------  -----------------  ---------------  ------------------  --------------  ---------------  -------------------------------\n",
       "     2017-11-13 22:26:47  0.694 sec   0.0                0.490427762858   0.674064263401      0.5             1.0              0.597368421053\n",
       "     2017-11-13 22:26:47  0.698 sec   1.0                0.468619074637   0.630722536895      0.889306383346  2.48366013072    0.205263157895\n",
       "     2017-11-13 22:26:47  0.702 sec   2.0                0.451185464277   0.597275528716      0.896878869022  2.48366013072    0.186842105263\n",
       "     2017-11-13 22:26:47  0.705 sec   3.0                0.436451698786   0.569531355681      0.89898073767   2.48366013072    0.181578947368\n",
       "     2017-11-13 22:26:47  0.708 sec   4.0                0.42350586729    0.545448639588      0.903184474965  2.48366013072    0.168421052632\n",
       "---  ---                  ---         ---                ---              ---                 ---             ---              ---\n",
       "     2017-11-13 22:26:47  0.929 sec   46.0               0.260798063771   0.25665171288       0.985776395727  2.48366013072    0.0631578947368\n",
       "     2017-11-13 22:26:47  0.934 sec   47.0               0.257916552548   0.252391619428      0.986668970084  2.48366013072    0.0657894736842\n",
       "     2017-11-13 22:26:47  0.940 sec   48.0               0.257057914235   0.250889978828      0.986697762806  2.48366013072    0.0631578947368\n",
       "     2017-11-13 22:26:47  0.946 sec   49.0               0.253522031578   0.245915459067      0.988051020702  2.48366013072    0.0631578947368\n",
       "     2017-11-13 22:26:47  0.951 sec   50.0               0.252559503025   0.244491796997      0.98825256975   2.48366013072    0.0631578947368"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>GLEASON</td>\n",
       "<td>110.3258133</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3229987</td></tr>\n",
       "<tr><td>ID</td>\n",
       "<td>58.6968040</td>\n",
       "<td>0.5320315</td>\n",
       "<td>0.1718455</td></tr>\n",
       "<tr><td>PSA</td>\n",
       "<td>57.7674637</td>\n",
       "<td>0.5236079</td>\n",
       "<td>0.1691247</td></tr>\n",
       "<tr><td>VOL</td>\n",
       "<td>40.0885315</td>\n",
       "<td>0.3633649</td>\n",
       "<td>0.1173664</td></tr>\n",
       "<tr><td>DPROS</td>\n",
       "<td>34.9556313</td>\n",
       "<td>0.3168400</td>\n",
       "<td>0.1023389</td></tr>\n",
       "<tr><td>AGE</td>\n",
       "<td>31.4995918</td>\n",
       "<td>0.2855142</td>\n",
       "<td>0.0922207</td></tr>\n",
       "<tr><td>DCAPS</td>\n",
       "<td>7.1565890</td>\n",
       "<td>0.0648678</td>\n",
       "<td>0.0209522</td></tr>\n",
       "<tr><td>RACE</td>\n",
       "<td>1.0769546</td>\n",
       "<td>0.0097616</td>\n",
       "<td>0.0031530</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  ------------\n",
       "GLEASON     110.326                1                    0.322999\n",
       "ID          58.6968                0.532031             0.171845\n",
       "PSA         57.7675                0.523608             0.169125\n",
       "VOL         40.0885                0.363365             0.117366\n",
       "DPROS       34.9556                0.31684              0.102339\n",
       "AGE         31.4996                0.285514             0.0922207\n",
       "DCAPS       7.15659                0.0648678            0.0209522\n",
       "RACE        1.07695                0.00976158           0.00315298"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model_with_training_and_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Building Gradient Boosting (GBM) -  Regression model with training and \n",
    "#  validation data and for that reason we need to split training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_gbm_train, df_gbm_valid, df_gbm_test = train_df.split_frame(ratios=[0.8,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: understanding the row count into original andsplit object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(380, 9)\n",
      "(304, 9)\n",
      "(38, 9)\n",
      "(38, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(df_gbm_train.shape)\n",
    "print(df_gbm_valid.shape)\n",
    "print(df_gbm_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#:Building Gradient Boosting (GBM) -  Regression model with training and validation data now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_model_with_training_and_validtion = H2OGradientBoostingEstimator()\n",
    "gbm_model_with_training_and_validtion.train(x = features, y = response, \n",
    "                                            training_frame=df_gbm_train, \n",
    "                                            validation_frame=df_gbm_valid,\n",
    "                                           model_id = \"glm_model_with_training_and_validtion_python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  glm_model_with_training_and_validtion_python\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0548119375726\n",
      "RMSE: 0.234119494217\n",
      "LogLoss: 0.223578775628\n",
      "Mean Per-Class Error: 0.030017921147\n",
      "AUC: 0.99520609319\n",
      "Gini: 0.99041218638\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.433295291885: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>175.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0278</td>\n",
       "<td> (5.0/180.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>4.0</td>\n",
       "<td>120.0</td>\n",
       "<td>0.0323</td>\n",
       "<td> (4.0/124.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>179.0</td>\n",
       "<td>125.0</td>\n",
       "<td>0.0296</td>\n",
       "<td> (9.0/304.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "0      175  5    0.0278   (5.0/180.0)\n",
       "1      4    120  0.0323   (4.0/124.0)\n",
       "Total  179  125  0.0296   (9.0/304.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4332953</td>\n",
       "<td>0.9638554</td>\n",
       "<td>124.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.4332953</td>\n",
       "<td>0.9661836</td>\n",
       "<td>124.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5733132</td>\n",
       "<td>0.9692029</td>\n",
       "<td>106.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4332953</td>\n",
       "<td>0.9703947</td>\n",
       "<td>124.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9792875</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.3123540</td>\n",
       "<td>1.0</td>\n",
       "<td>146.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9792875</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4332953</td>\n",
       "<td>0.9388082</td>\n",
       "<td>124.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4332953</td>\n",
       "<td>0.9677419</td>\n",
       "<td>124.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4332953</td>\n",
       "<td>0.9699821</td>\n",
       "<td>124.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.433295     0.963855  124\n",
       "max f2                       0.433295     0.966184  124\n",
       "max f0point5                 0.573313     0.969203  106\n",
       "max accuracy                 0.433295     0.970395  124\n",
       "max precision                0.979287     1         0\n",
       "max recall                   0.312354     1         146\n",
       "max specificity              0.979287     1         0\n",
       "max absolute_mcc             0.433295     0.938808  124\n",
       "max min_per_class_accuracy   0.433295     0.967742  124\n",
       "max mean_per_class_accuracy  0.433295     0.969982  124"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 40.79 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0131579</td>\n",
       "<td>0.9628819</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0322581</td>\n",
       "<td>0.0322581</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0230263</td>\n",
       "<td>0.9533590</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0241935</td>\n",
       "<td>0.0564516</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0328947</td>\n",
       "<td>0.9502933</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0241935</td>\n",
       "<td>0.0806452</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0427632</td>\n",
       "<td>0.9432361</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0241935</td>\n",
       "<td>0.1048387</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0526316</td>\n",
       "<td>0.9418574</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0241935</td>\n",
       "<td>0.1290323</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1019737</td>\n",
       "<td>0.9158052</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1209677</td>\n",
       "<td>0.25</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1513158</td>\n",
       "<td>0.8692245</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1209677</td>\n",
       "<td>0.3709677</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2006579</td>\n",
       "<td>0.8105281</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1209677</td>\n",
       "<td>0.4919355</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2993421</td>\n",
       "<td>0.7075336</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2419355</td>\n",
       "<td>0.7338710</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4013158</td>\n",
       "<td>0.4559975</td>\n",
       "<td>2.1352758</td>\n",
       "<td>2.3712322</td>\n",
       "<td>0.8709677</td>\n",
       "<td>0.9672131</td>\n",
       "<td>0.2177419</td>\n",
       "<td>0.9516129</td>\n",
       "<td>113.5275754</td>\n",
       "<td>137.1232152</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.2705564</td>\n",
       "<td>0.4903226</td>\n",
       "<td>2.0</td>\n",
       "<td>0.2</td>\n",
       "<td>0.8157895</td>\n",
       "<td>0.0483871</td>\n",
       "<td>1.0</td>\n",
       "<td>-50.9677419</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5986842</td>\n",
       "<td>0.1836534</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6703297</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6813187</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.0329670</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7006579</td>\n",
       "<td>0.1322374</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4272300</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5821596</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.7230047</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7993421</td>\n",
       "<td>0.0793147</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2510288</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5102881</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1028807</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8980263</td>\n",
       "<td>0.0448171</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1135531</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4542125</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.3553114</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0079513</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4078947</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0131579                   0.962882           2.45161   2.45161            1                1                           0.0322581       0.0322581                  145.161   145.161\n",
       "    2        0.0230263                   0.953359           2.45161   2.45161            1                1                           0.0241935       0.0564516                  145.161   145.161\n",
       "    3        0.0328947                   0.950293           2.45161   2.45161            1                1                           0.0241935       0.0806452                  145.161   145.161\n",
       "    4        0.0427632                   0.943236           2.45161   2.45161            1                1                           0.0241935       0.104839                   145.161   145.161\n",
       "    5        0.0526316                   0.941857           2.45161   2.45161            1                1                           0.0241935       0.129032                   145.161   145.161\n",
       "    6        0.101974                    0.915805           2.45161   2.45161            1                1                           0.120968        0.25                       145.161   145.161\n",
       "    7        0.151316                    0.869225           2.45161   2.45161            1                1                           0.120968        0.370968                   145.161   145.161\n",
       "    8        0.200658                    0.810528           2.45161   2.45161            1                1                           0.120968        0.491935                   145.161   145.161\n",
       "    9        0.299342                    0.707534           2.45161   2.45161            1                1                           0.241935        0.733871                   145.161   145.161\n",
       "    10       0.401316                    0.455998           2.13528   2.37123            0.870968         0.967213                    0.217742        0.951613                   113.528   137.123\n",
       "    11       0.5                         0.270556           0.490323  2                  0.2              0.815789                    0.0483871       1                          -50.9677  100\n",
       "    12       0.598684                    0.183653           0         1.67033            0                0.681319                    0               1                          -100      67.033\n",
       "    13       0.700658                    0.132237           0         1.42723            0                0.58216                     0               1                          -100      42.723\n",
       "    14       0.799342                    0.0793147          0         1.25103            0                0.510288                    0               1                          -100      25.1029\n",
       "    15       0.898026                    0.0448171          0         1.11355            0                0.454212                    0               1                          -100      11.3553\n",
       "    16       1                           0.00795132         0         1                  0                0.407895                    0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.152755729065\n",
      "RMSE: 0.390839774159\n",
      "LogLoss: 0.481813619133\n",
      "Mean Per-Class Error: 0.196923076923\n",
      "AUC: 0.809230769231\n",
      "Gini: 0.618461538462\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.420686001908: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>19.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.24</td>\n",
       "<td> (6.0/25.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>2.0</td>\n",
       "<td>11.0</td>\n",
       "<td>0.1538</td>\n",
       "<td> (2.0/13.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>21.0</td>\n",
       "<td>17.0</td>\n",
       "<td>0.2105</td>\n",
       "<td> (8.0/38.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ----------\n",
       "0      19   6    0.24     (6.0/25.0)\n",
       "1      2    11   0.1538   (2.0/13.0)\n",
       "Total  21   17   0.2105   (8.0/38.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4206860</td>\n",
       "<td>0.7333333</td>\n",
       "<td>16.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.4206860</td>\n",
       "<td>0.7971014</td>\n",
       "<td>16.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6842872</td>\n",
       "<td>0.8108108</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6842872</td>\n",
       "<td>0.8157895</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9709371</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0246933</td>\n",
       "<td>1.0</td>\n",
       "<td>36.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9709371</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.6842872</td>\n",
       "<td>0.6004806</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4559573</td>\n",
       "<td>0.7692308</td>\n",
       "<td>14.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4206860</td>\n",
       "<td>0.8030769</td>\n",
       "<td>16.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.420686     0.733333  16\n",
       "max f2                       0.420686     0.797101  16\n",
       "max f0point5                 0.684287     0.810811  5\n",
       "max accuracy                 0.684287     0.815789  5\n",
       "max precision                0.970937     1         0\n",
       "max recall                   0.0246933    1         36\n",
       "max specificity              0.970937     1         0\n",
       "max absolute_mcc             0.684287     0.600481  5\n",
       "max min_per_class_accuracy   0.455957     0.769231  14\n",
       "max mean_per_class_accuracy  0.420686     0.803077  16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 34.21 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0263158</td>\n",
       "<td>0.9671841</td>\n",
       "<td>2.9230769</td>\n",
       "<td>2.9230769</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.0769231</td>\n",
       "<td>192.3076923</td>\n",
       "<td>192.3076923</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0263158</td>\n",
       "<td>0.9634310</td>\n",
       "<td>0.0</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0769231</td>\n",
       "<td>-100.0</td>\n",
       "<td>192.3076923</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0526316</td>\n",
       "<td>0.9515437</td>\n",
       "<td>2.9230769</td>\n",
       "<td>2.9230769</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.1538462</td>\n",
       "<td>192.3076923</td>\n",
       "<td>192.3076923</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0526316</td>\n",
       "<td>0.9204302</td>\n",
       "<td>0.0</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1538462</td>\n",
       "<td>-100.0</td>\n",
       "<td>192.3076923</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0526316</td>\n",
       "<td>0.8893168</td>\n",
       "<td>0.0</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1538462</td>\n",
       "<td>-100.0</td>\n",
       "<td>192.3076923</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1052632</td>\n",
       "<td>0.7978554</td>\n",
       "<td>2.9230769</td>\n",
       "<td>2.9230769</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1538462</td>\n",
       "<td>0.3076923</td>\n",
       "<td>192.3076923</td>\n",
       "<td>192.3076923</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1578947</td>\n",
       "<td>0.6665591</td>\n",
       "<td>2.9230769</td>\n",
       "<td>2.9230769</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1538462</td>\n",
       "<td>0.4615385</td>\n",
       "<td>192.3076923</td>\n",
       "<td>192.3076923</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2105263</td>\n",
       "<td>0.6062020</td>\n",
       "<td>0.0</td>\n",
       "<td>2.1923077</td>\n",
       "<td>0.0</td>\n",
       "<td>0.75</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4615385</td>\n",
       "<td>-100.0</td>\n",
       "<td>119.2307692</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3157895</td>\n",
       "<td>0.4972917</td>\n",
       "<td>0.7307692</td>\n",
       "<td>1.7051282</td>\n",
       "<td>0.25</td>\n",
       "<td>0.5833333</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.5384615</td>\n",
       "<td>-26.9230769</td>\n",
       "<td>70.5128205</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3947368</td>\n",
       "<td>0.4406607</td>\n",
       "<td>2.9230769</td>\n",
       "<td>1.9487179</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.2307692</td>\n",
       "<td>0.7692308</td>\n",
       "<td>192.3076923</td>\n",
       "<td>94.8717949</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.3210774</td>\n",
       "<td>0.7307692</td>\n",
       "<td>1.6923077</td>\n",
       "<td>0.25</td>\n",
       "<td>0.5789474</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.8461538</td>\n",
       "<td>-26.9230769</td>\n",
       "<td>69.2307692</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6052632</td>\n",
       "<td>0.1387541</td>\n",
       "<td>0.0</td>\n",
       "<td>1.3979933</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4782609</td>\n",
       "<td>0.0</td>\n",
       "<td>0.8461538</td>\n",
       "<td>-100.0</td>\n",
       "<td>39.7993311</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6842105</td>\n",
       "<td>0.0647476</td>\n",
       "<td>0.9743590</td>\n",
       "<td>1.3491124</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.4615385</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.9230769</td>\n",
       "<td>-2.5641026</td>\n",
       "<td>34.9112426</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7894737</td>\n",
       "<td>0.0540283</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1692308</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9230769</td>\n",
       "<td>-100.0</td>\n",
       "<td>16.9230769</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8947368</td>\n",
       "<td>0.0368757</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0316742</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3529412</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9230769</td>\n",
       "<td>-100.0</td>\n",
       "<td>3.1674208</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0090053</td>\n",
       "<td>0.7307692</td>\n",
       "<td>1.0</td>\n",
       "<td>0.25</td>\n",
       "<td>0.3421053</td>\n",
       "<td>0.0769231</td>\n",
       "<td>1.0</td>\n",
       "<td>-26.9230769</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0263158                   0.967184           2.92308   2.92308            1                1                           0.0769231       0.0769231                  192.308   192.308\n",
       "    2        0.0263158                   0.963431           0         2.92308            0                1                           0               0.0769231                  -100      192.308\n",
       "    3        0.0526316                   0.951544           2.92308   2.92308            1                1                           0.0769231       0.153846                   192.308   192.308\n",
       "    4        0.0526316                   0.92043            0         2.92308            0                1                           0               0.153846                   -100      192.308\n",
       "    5        0.0526316                   0.889317           0         2.92308            0                1                           0               0.153846                   -100      192.308\n",
       "    6        0.105263                    0.797855           2.92308   2.92308            1                1                           0.153846        0.307692                   192.308   192.308\n",
       "    7        0.157895                    0.666559           2.92308   2.92308            1                1                           0.153846        0.461538                   192.308   192.308\n",
       "    8        0.210526                    0.606202           0         2.19231            0                0.75                        0               0.461538                   -100      119.231\n",
       "    9        0.315789                    0.497292           0.730769  1.70513            0.25             0.583333                    0.0769231       0.538462                   -26.9231  70.5128\n",
       "    10       0.394737                    0.440661           2.92308   1.94872            1                0.666667                    0.230769        0.769231                   192.308   94.8718\n",
       "    11       0.5                         0.321077           0.730769  1.69231            0.25             0.578947                    0.0769231       0.846154                   -26.9231  69.2308\n",
       "    12       0.605263                    0.138754           0         1.39799            0                0.478261                    0               0.846154                   -100      39.7993\n",
       "    13       0.684211                    0.0647476          0.974359  1.34911            0.333333         0.461538                    0.0769231       0.923077                   -2.5641   34.9112\n",
       "    14       0.789474                    0.0540283          0         1.16923            0                0.4                         0               0.923077                   -100      16.9231\n",
       "    15       0.894737                    0.0368757          0         1.03167            0                0.352941                    0               0.923077                   -100      3.16742\n",
       "    16       1                           0.00900531         0.730769  1                  0.25             0.342105                    0.0769231       1                          -26.9231  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:27:52</td>\n",
       "<td> 0.001 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4914434</td>\n",
       "<td>0.6760831</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5921053</td>\n",
       "<td>0.4789546</td>\n",
       "<td>0.6515650</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6578947</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:27:52</td>\n",
       "<td> 0.005 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4720114</td>\n",
       "<td>0.6374387</td>\n",
       "<td>0.8644041</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.2269737</td>\n",
       "<td>0.4650639</td>\n",
       "<td>0.6244840</td>\n",
       "<td>0.78</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.2368421</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:27:52</td>\n",
       "<td> 0.009 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.4554601</td>\n",
       "<td>0.6056158</td>\n",
       "<td>0.8869624</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.2171053</td>\n",
       "<td>0.4488147</td>\n",
       "<td>0.5937507</td>\n",
       "<td>0.8246154</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.2105263</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:27:52</td>\n",
       "<td> 0.013 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.4398059</td>\n",
       "<td>0.5760860</td>\n",
       "<td>0.8940412</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.2006579</td>\n",
       "<td>0.4337890</td>\n",
       "<td>0.5660393</td>\n",
       "<td>0.8446154</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.1315789</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:27:52</td>\n",
       "<td> 0.016 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.4278322</td>\n",
       "<td>0.5539058</td>\n",
       "<td>0.9040995</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.2039474</td>\n",
       "<td>0.4218901</td>\n",
       "<td>0.5441911</td>\n",
       "<td>0.8876923</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.1578947</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:27:52</td>\n",
       "<td> 0.224 sec</td>\n",
       "<td>46.0</td>\n",
       "<td>0.2413698</td>\n",
       "<td>0.2339888</td>\n",
       "<td>0.9938620</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.0394737</td>\n",
       "<td>0.3905465</td>\n",
       "<td>0.4824366</td>\n",
       "<td>0.8092308</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.2105263</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:27:52</td>\n",
       "<td> 0.230 sec</td>\n",
       "<td>47.0</td>\n",
       "<td>0.2398180</td>\n",
       "<td>0.2316915</td>\n",
       "<td>0.9942652</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.0361842</td>\n",
       "<td>0.3930096</td>\n",
       "<td>0.4865162</td>\n",
       "<td>0.8030769</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.2105263</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:27:52</td>\n",
       "<td> 0.236 sec</td>\n",
       "<td>48.0</td>\n",
       "<td>0.2385228</td>\n",
       "<td>0.2295585</td>\n",
       "<td>0.9940860</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.0361842</td>\n",
       "<td>0.3928504</td>\n",
       "<td>0.4853373</td>\n",
       "<td>0.8030769</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.2105263</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:27:52</td>\n",
       "<td> 0.242 sec</td>\n",
       "<td>49.0</td>\n",
       "<td>0.2372900</td>\n",
       "<td>0.2277650</td>\n",
       "<td>0.9944892</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.0361842</td>\n",
       "<td>0.3919804</td>\n",
       "<td>0.4835920</td>\n",
       "<td>0.8030769</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.2105263</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:27:52</td>\n",
       "<td> 0.249 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.2341195</td>\n",
       "<td>0.2235788</td>\n",
       "<td>0.9952061</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.0296053</td>\n",
       "<td>0.3908398</td>\n",
       "<td>0.4818136</td>\n",
       "<td>0.8092308</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.2105263</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_lift    validation_classification_error\n",
       "---  -------------------  ----------  -----------------  ---------------  ------------------  --------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -----------------  ---------------------------------\n",
       "     2017-11-13 22:27:52  0.001 sec   0.0                0.491443405184   0.676083137935      0.5             1.0              0.592105263158                   0.478954597979     0.651565027061        0.5               1.0                0.657894736842\n",
       "     2017-11-13 22:27:52  0.005 sec   1.0                0.47201136688    0.637438720533      0.864404121864  2.45161290323    0.226973684211                   0.465063859913     0.624484017531        0.78              2.92307692308      0.236842105263\n",
       "     2017-11-13 22:27:52  0.009 sec   2.0                0.455460131806   0.605615804428      0.886962365591  2.45161290323    0.217105263158                   0.448814670909     0.593750720034        0.824615384615    2.92307692308      0.210526315789\n",
       "     2017-11-13 22:27:52  0.013 sec   3.0                0.439805946936   0.576086017264      0.894041218638  2.45161290323    0.200657894737                   0.433788981793     0.566039257654        0.844615384615    2.92307692308      0.131578947368\n",
       "     2017-11-13 22:27:52  0.016 sec   4.0                0.427832214847   0.553905780061      0.904099462366  2.45161290323    0.203947368421                   0.421890125192     0.544191076593        0.887692307692    2.92307692308      0.157894736842\n",
       "---  ---                  ---         ---                ---              ---                 ---             ---              ---                              ---                ---                   ---               ---                ---\n",
       "     2017-11-13 22:27:52  0.224 sec   46.0               0.24136978177    0.233988756403      0.993862007168  2.45161290323    0.0394736842105                  0.39054650576      0.482436576318        0.809230769231    2.92307692308      0.210526315789\n",
       "     2017-11-13 22:27:52  0.230 sec   47.0               0.239818029435   0.231691518327      0.994265232975  2.45161290323    0.0361842105263                  0.393009617091     0.48651623121         0.803076923077    2.92307692308      0.210526315789\n",
       "     2017-11-13 22:27:52  0.236 sec   48.0               0.238522751147   0.229558475537      0.994086021505  2.45161290323    0.0361842105263                  0.39285041543      0.485337276163        0.803076923077    2.92307692308      0.210526315789\n",
       "     2017-11-13 22:27:52  0.242 sec   49.0               0.237290047562   0.22776499544       0.994489247312  2.45161290323    0.0361842105263                  0.391980378229     0.483591964311        0.803076923077    2.92307692308      0.210526315789\n",
       "     2017-11-13 22:27:52  0.249 sec   50.0               0.234119494217   0.223578775628      0.99520609319   2.45161290323    0.0296052631579                  0.390839774159     0.481813619133        0.809230769231    2.92307692308      0.210526315789"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>GLEASON</td>\n",
       "<td>73.4897232</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2549634</td></tr>\n",
       "<tr><td>PSA</td>\n",
       "<td>63.4471703</td>\n",
       "<td>0.8633475</td>\n",
       "<td>0.2201221</td></tr>\n",
       "<tr><td>ID</td>\n",
       "<td>57.4138336</td>\n",
       "<td>0.7812498</td>\n",
       "<td>0.1991901</td></tr>\n",
       "<tr><td>VOL</td>\n",
       "<td>50.6388054</td>\n",
       "<td>0.6890597</td>\n",
       "<td>0.1756850</td></tr>\n",
       "<tr><td>DPROS</td>\n",
       "<td>24.5224018</td>\n",
       "<td>0.3336848</td>\n",
       "<td>0.0850774</td></tr>\n",
       "<tr><td>AGE</td>\n",
       "<td>15.4116030</td>\n",
       "<td>0.2097110</td>\n",
       "<td>0.0534686</td></tr>\n",
       "<tr><td>DCAPS</td>\n",
       "<td>3.1581650</td>\n",
       "<td>0.0429742</td>\n",
       "<td>0.0109569</td></tr>\n",
       "<tr><td>RACE</td>\n",
       "<td>0.1546198</td>\n",
       "<td>0.0021040</td>\n",
       "<td>0.0005364</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  ------------\n",
       "GLEASON     73.4897                1                    0.254963\n",
       "PSA         63.4472                0.863348             0.220122\n",
       "ID          57.4138                0.78125              0.19919\n",
       "VOL         50.6388                0.68906              0.175685\n",
       "DPROS       24.5224                0.333685             0.0850774\n",
       "AGE         15.4116                0.209711             0.0534686\n",
       "DCAPS       3.15816                0.0429742            0.0109569\n",
       "RACE        0.15462                0.00210397           0.000536434"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model_with_training_and_validtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#:Building Gradient Boosting (GBM) -  Regression model with training and validation data now\n",
    "#  Setting key GBM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm_model_with_training_cv_config = H2OGradientBoostingEstimator(distribution=\"AUTO\",\n",
    "                                      ntrees=10,\n",
    "                                      max_depth=3,\n",
    "                                      min_rows=2,\n",
    "                                      learn_rate=0.2,\n",
    "                                      nfolds=5,\n",
    "                                      keep_cross_validation_predictions=True,\n",
    "                                      seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_model_with_training_cv_config.train(x = features, y = response, \n",
    "                                            training_frame=df_gbm_train, \n",
    "                                           model_id = \"glm_model_with_training_and_validtion_python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  glm_model_with_training_and_validtion_python\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.130611385751\n",
      "RMSE: 0.361401972534\n",
      "LogLoss: 0.426908083591\n",
      "Mean Per-Class Error: 0.15958781362\n",
      "AUC: 0.916129032258\n",
      "Gini: 0.832258064516\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.501700545623: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>169.0</td>\n",
       "<td>11.0</td>\n",
       "<td>0.0611</td>\n",
       "<td> (11.0/180.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>32.0</td>\n",
       "<td>92.0</td>\n",
       "<td>0.2581</td>\n",
       "<td> (32.0/124.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>201.0</td>\n",
       "<td>103.0</td>\n",
       "<td>0.1414</td>\n",
       "<td> (43.0/304.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      169  11   0.0611   (11.0/180.0)\n",
       "1      32   92   0.2581   (32.0/124.0)\n",
       "Total  201  103  0.1414   (43.0/304.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.5017005</td>\n",
       "<td>0.8105727</td>\n",
       "<td>66.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3235305</td>\n",
       "<td>0.8536585</td>\n",
       "<td>107.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5017005</td>\n",
       "<td>0.8582090</td>\n",
       "<td>66.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5017005</td>\n",
       "<td>0.8585526</td>\n",
       "<td>66.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.8693852</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1944091</td>\n",
       "<td>1.0</td>\n",
       "<td>164.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.8693852</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.5017005</td>\n",
       "<td>0.7069123</td>\n",
       "<td>66.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3673496</td>\n",
       "<td>0.8166667</td>\n",
       "<td>92.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.5017005</td>\n",
       "<td>0.8404122</td>\n",
       "<td>66.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.501701     0.810573  66\n",
       "max f2                       0.323531     0.853659  107\n",
       "max f0point5                 0.501701     0.858209  66\n",
       "max accuracy                 0.501701     0.858553  66\n",
       "max precision                0.869385     1         0\n",
       "max recall                   0.194409     1         164\n",
       "max specificity              0.869385     1         0\n",
       "max absolute_mcc             0.501701     0.706912  66\n",
       "max min_per_class_accuracy   0.36735      0.816667  92\n",
       "max mean_per_class_accuracy  0.501701     0.840412  66"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 40.79 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0131579</td>\n",
       "<td>0.8443104</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0322581</td>\n",
       "<td>0.0322581</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0263158</td>\n",
       "<td>0.8369140</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0322581</td>\n",
       "<td>0.0645161</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0328947</td>\n",
       "<td>0.8332900</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0161290</td>\n",
       "<td>0.0806452</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0427632</td>\n",
       "<td>0.8292500</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0241935</td>\n",
       "<td>0.1048387</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0526316</td>\n",
       "<td>0.8234718</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0241935</td>\n",
       "<td>0.1290323</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1019737</td>\n",
       "<td>0.7854583</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1209677</td>\n",
       "<td>0.25</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1513158</td>\n",
       "<td>0.7274284</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1209677</td>\n",
       "<td>0.3709677</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2006579</td>\n",
       "<td>0.6405118</td>\n",
       "<td>2.1247312</td>\n",
       "<td>2.3712322</td>\n",
       "<td>0.8666667</td>\n",
       "<td>0.9672131</td>\n",
       "<td>0.1048387</td>\n",
       "<td>0.4758065</td>\n",
       "<td>112.4731183</td>\n",
       "<td>137.1232152</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2993421</td>\n",
       "<td>0.5322161</td>\n",
       "<td>1.9612903</td>\n",
       "<td>2.2360865</td>\n",
       "<td>0.8</td>\n",
       "<td>0.9120879</td>\n",
       "<td>0.1935484</td>\n",
       "<td>0.6693548</td>\n",
       "<td>96.1290323</td>\n",
       "<td>123.6086494</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4013158</td>\n",
       "<td>0.4207128</td>\n",
       "<td>1.1862643</td>\n",
       "<td>1.9693284</td>\n",
       "<td>0.4838710</td>\n",
       "<td>0.8032787</td>\n",
       "<td>0.1209677</td>\n",
       "<td>0.7903226</td>\n",
       "<td>18.6264308</td>\n",
       "<td>96.9328398</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.3319850</td>\n",
       "<td>0.8172043</td>\n",
       "<td>1.7419355</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.7105263</td>\n",
       "<td>0.0806452</td>\n",
       "<td>0.8709677</td>\n",
       "<td>-18.2795699</td>\n",
       "<td>74.1935484</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6019737</td>\n",
       "<td>0.2892348</td>\n",
       "<td>0.5535900</td>\n",
       "<td>1.5406311</td>\n",
       "<td>0.2258065</td>\n",
       "<td>0.6284153</td>\n",
       "<td>0.0564516</td>\n",
       "<td>0.9274194</td>\n",
       "<td>-44.6409990</td>\n",
       "<td>54.0631059</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7039474</td>\n",
       "<td>0.2535699</td>\n",
       "<td>0.4745057</td>\n",
       "<td>1.3861923</td>\n",
       "<td>0.1935484</td>\n",
       "<td>0.5654206</td>\n",
       "<td>0.0483871</td>\n",
       "<td>0.9758065</td>\n",
       "<td>-52.5494277</td>\n",
       "<td>38.6192342</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7993421</td>\n",
       "<td>0.1974429</td>\n",
       "<td>0.1690768</td>\n",
       "<td>1.2409399</td>\n",
       "<td>0.0689655</td>\n",
       "<td>0.5061728</td>\n",
       "<td>0.0161290</td>\n",
       "<td>0.9919355</td>\n",
       "<td>-83.0923248</td>\n",
       "<td>24.0939865</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8980263</td>\n",
       "<td>0.1527119</td>\n",
       "<td>0.0817204</td>\n",
       "<td>1.1135531</td>\n",
       "<td>0.0333333</td>\n",
       "<td>0.4542125</td>\n",
       "<td>0.0080645</td>\n",
       "<td>1.0</td>\n",
       "<td>-91.8279570</td>\n",
       "<td>11.3553114</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0774773</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4078947</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0131579                   0.84431            2.45161    2.45161            1                1                           0.0322581       0.0322581                  145.161   145.161\n",
       "    2        0.0263158                   0.836914           2.45161    2.45161            1                1                           0.0322581       0.0645161                  145.161   145.161\n",
       "    3        0.0328947                   0.83329            2.45161    2.45161            1                1                           0.016129        0.0806452                  145.161   145.161\n",
       "    4        0.0427632                   0.82925            2.45161    2.45161            1                1                           0.0241935       0.104839                   145.161   145.161\n",
       "    5        0.0526316                   0.823472           2.45161    2.45161            1                1                           0.0241935       0.129032                   145.161   145.161\n",
       "    6        0.101974                    0.785458           2.45161    2.45161            1                1                           0.120968        0.25                       145.161   145.161\n",
       "    7        0.151316                    0.727428           2.45161    2.45161            1                1                           0.120968        0.370968                   145.161   145.161\n",
       "    8        0.200658                    0.640512           2.12473    2.37123            0.866667         0.967213                    0.104839        0.475806                   112.473   137.123\n",
       "    9        0.299342                    0.532216           1.96129    2.23609            0.8              0.912088                    0.193548        0.669355                   96.129    123.609\n",
       "    10       0.401316                    0.420713           1.18626    1.96933            0.483871         0.803279                    0.120968        0.790323                   18.6264   96.9328\n",
       "    11       0.5                         0.331985           0.817204   1.74194            0.333333         0.710526                    0.0806452       0.870968                   -18.2796  74.1935\n",
       "    12       0.601974                    0.289235           0.55359    1.54063            0.225806         0.628415                    0.0564516       0.927419                   -44.641   54.0631\n",
       "    13       0.703947                    0.25357            0.474506   1.38619            0.193548         0.565421                    0.0483871       0.975806                   -52.5494  38.6192\n",
       "    14       0.799342                    0.197443           0.169077   1.24094            0.0689655        0.506173                    0.016129        0.991935                   -83.0923  24.094\n",
       "    15       0.898026                    0.152712           0.0817204  1.11355            0.0333333        0.454212                    0.00806452      1                          -91.828   11.3553\n",
       "    16       1                           0.0774773          0          1                  0                0.407895                    0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.194813105492\n",
      "RMSE: 0.441376376228\n",
      "LogLoss: 0.575641820282\n",
      "Mean Per-Class Error: 0.292025089606\n",
      "AUC: 0.756563620072\n",
      "Gini: 0.513127240143\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.305673209134: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>100.0</td>\n",
       "<td>80.0</td>\n",
       "<td>0.4444</td>\n",
       "<td> (80.0/180.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>23.0</td>\n",
       "<td>101.0</td>\n",
       "<td>0.1855</td>\n",
       "<td> (23.0/124.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>123.0</td>\n",
       "<td>181.0</td>\n",
       "<td>0.3388</td>\n",
       "<td> (103.0/304.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -------------\n",
       "0      100  80   0.4444   (80.0/180.0)\n",
       "1      23   101  0.1855   (23.0/124.0)\n",
       "Total  123  181  0.3388   (103.0/304.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3056732</td>\n",
       "<td>0.6622951</td>\n",
       "<td>158.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1501359</td>\n",
       "<td>0.7922078</td>\n",
       "<td>235.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5003035</td>\n",
       "<td>0.6774809</td>\n",
       "<td>86.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5003035</td>\n",
       "<td>0.7302632</td>\n",
       "<td>86.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.8917895</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0935315</td>\n",
       "<td>1.0</td>\n",
       "<td>258.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.8917895</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.5003035</td>\n",
       "<td>0.4303975</td>\n",
       "<td>86.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3938076</td>\n",
       "<td>0.6888889</td>\n",
       "<td>123.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4674099</td>\n",
       "<td>0.7079749</td>\n",
       "<td>95.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.305673     0.662295  158\n",
       "max f2                       0.150136     0.792208  235\n",
       "max f0point5                 0.500304     0.677481  86\n",
       "max accuracy                 0.500304     0.730263  86\n",
       "max precision                0.891789     1         0\n",
       "max recall                   0.0935315    1         258\n",
       "max specificity              0.891789     1         0\n",
       "max absolute_mcc             0.500304     0.430397  86\n",
       "max min_per_class_accuracy   0.393808     0.688889  123\n",
       "max mean_per_class_accuracy  0.46741      0.707975  95"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 40.79 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0131579</td>\n",
       "<td>0.8746550</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0322581</td>\n",
       "<td>0.0322581</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0230263</td>\n",
       "<td>0.8210769</td>\n",
       "<td>0.8172043</td>\n",
       "<td>1.7511521</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.7142857</td>\n",
       "<td>0.0080645</td>\n",
       "<td>0.0403226</td>\n",
       "<td>-18.2795699</td>\n",
       "<td>75.1152074</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0328947</td>\n",
       "<td>0.8097297</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.9612903</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0241935</td>\n",
       "<td>0.0645161</td>\n",
       "<td>145.1612903</td>\n",
       "<td>96.1290323</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0427632</td>\n",
       "<td>0.8061051</td>\n",
       "<td>0.8172043</td>\n",
       "<td>1.6972705</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.6923077</td>\n",
       "<td>0.0080645</td>\n",
       "<td>0.0725806</td>\n",
       "<td>-18.2795699</td>\n",
       "<td>69.7270471</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0526316</td>\n",
       "<td>0.7815192</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.8387097</td>\n",
       "<td>1.0</td>\n",
       "<td>0.75</td>\n",
       "<td>0.0241935</td>\n",
       "<td>0.0967742</td>\n",
       "<td>145.1612903</td>\n",
       "<td>83.8709677</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1019737</td>\n",
       "<td>0.7059889</td>\n",
       "<td>1.9612903</td>\n",
       "<td>1.8980229</td>\n",
       "<td>0.8</td>\n",
       "<td>0.7741935</td>\n",
       "<td>0.0967742</td>\n",
       "<td>0.1935484</td>\n",
       "<td>96.1290323</td>\n",
       "<td>89.8022893</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1513158</td>\n",
       "<td>0.6549893</td>\n",
       "<td>2.2881720</td>\n",
       "<td>2.0252454</td>\n",
       "<td>0.9333333</td>\n",
       "<td>0.8260870</td>\n",
       "<td>0.1129032</td>\n",
       "<td>0.3064516</td>\n",
       "<td>128.8172043</td>\n",
       "<td>102.5245442</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2072368</td>\n",
       "<td>0.6002565</td>\n",
       "<td>1.1537002</td>\n",
       "<td>1.7900666</td>\n",
       "<td>0.4705882</td>\n",
       "<td>0.7301587</td>\n",
       "<td>0.0645161</td>\n",
       "<td>0.3709677</td>\n",
       "<td>15.3700190</td>\n",
       "<td>79.0066564</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2993421</td>\n",
       "<td>0.5140543</td>\n",
       "<td>1.5760369</td>\n",
       "<td>1.7242113</td>\n",
       "<td>0.6428571</td>\n",
       "<td>0.7032967</td>\n",
       "<td>0.1451613</td>\n",
       "<td>0.5161290</td>\n",
       "<td>57.6036866</td>\n",
       "<td>72.4211273</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4046053</td>\n",
       "<td>0.4383256</td>\n",
       "<td>1.2258065</td>\n",
       "<td>1.5945450</td>\n",
       "<td>0.5</td>\n",
       "<td>0.6504065</td>\n",
       "<td>0.1290323</td>\n",
       "<td>0.6451613</td>\n",
       "<td>22.5806452</td>\n",
       "<td>59.4544978</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.3818219</td>\n",
       "<td>0.8453838</td>\n",
       "<td>1.4516129</td>\n",
       "<td>0.3448276</td>\n",
       "<td>0.5921053</td>\n",
       "<td>0.0806452</td>\n",
       "<td>0.7258065</td>\n",
       "<td>-15.4616240</td>\n",
       "<td>45.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5986842</td>\n",
       "<td>0.3019659</td>\n",
       "<td>0.8989247</td>\n",
       "<td>1.3605105</td>\n",
       "<td>0.3666667</td>\n",
       "<td>0.5549451</td>\n",
       "<td>0.0887097</td>\n",
       "<td>0.8145161</td>\n",
       "<td>-10.1075269</td>\n",
       "<td>36.0510457</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7006579</td>\n",
       "<td>0.2648859</td>\n",
       "<td>0.6326743</td>\n",
       "<td>1.2545813</td>\n",
       "<td>0.2580645</td>\n",
       "<td>0.5117371</td>\n",
       "<td>0.0645161</td>\n",
       "<td>0.8790323</td>\n",
       "<td>-36.7325702</td>\n",
       "<td>25.4581251</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7993421</td>\n",
       "<td>0.2119091</td>\n",
       "<td>0.2451613</td>\n",
       "<td>1.1299615</td>\n",
       "<td>0.1</td>\n",
       "<td>0.4609053</td>\n",
       "<td>0.0241935</td>\n",
       "<td>0.9032258</td>\n",
       "<td>-75.4838710</td>\n",
       "<td>12.9961503</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8980263</td>\n",
       "<td>0.1507467</td>\n",
       "<td>0.7354839</td>\n",
       "<td>1.0866123</td>\n",
       "<td>0.3</td>\n",
       "<td>0.4432234</td>\n",
       "<td>0.0725806</td>\n",
       "<td>0.9758065</td>\n",
       "<td>-26.4516129</td>\n",
       "<td>8.6612312</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0737707</td>\n",
       "<td>0.2372529</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0967742</td>\n",
       "<td>0.4078947</td>\n",
       "<td>0.0241935</td>\n",
       "<td>1.0</td>\n",
       "<td>-76.2747138</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0131579                   0.874655           2.45161   2.45161            1                1                           0.0322581       0.0322581                  145.161   145.161\n",
       "    2        0.0230263                   0.821077           0.817204  1.75115            0.333333         0.714286                    0.00806452      0.0403226                  -18.2796  75.1152\n",
       "    3        0.0328947                   0.80973            2.45161   1.96129            1                0.8                         0.0241935       0.0645161                  145.161   96.129\n",
       "    4        0.0427632                   0.806105           0.817204  1.69727            0.333333         0.692308                    0.00806452      0.0725806                  -18.2796  69.727\n",
       "    5        0.0526316                   0.781519           2.45161   1.83871            1                0.75                        0.0241935       0.0967742                  145.161   83.871\n",
       "    6        0.101974                    0.705989           1.96129   1.89802            0.8              0.774194                    0.0967742       0.193548                   96.129    89.8023\n",
       "    7        0.151316                    0.654989           2.28817   2.02525            0.933333         0.826087                    0.112903        0.306452                   128.817   102.525\n",
       "    8        0.207237                    0.600256           1.1537    1.79007            0.470588         0.730159                    0.0645161       0.370968                   15.37     79.0067\n",
       "    9        0.299342                    0.514054           1.57604   1.72421            0.642857         0.703297                    0.145161        0.516129                   57.6037   72.4211\n",
       "    10       0.404605                    0.438326           1.22581   1.59454            0.5              0.650407                    0.129032        0.645161                   22.5806   59.4545\n",
       "    11       0.5                         0.381822           0.845384  1.45161            0.344828         0.592105                    0.0806452       0.725806                   -15.4616  45.1613\n",
       "    12       0.598684                    0.301966           0.898925  1.36051            0.366667         0.554945                    0.0887097       0.814516                   -10.1075  36.051\n",
       "    13       0.700658                    0.264886           0.632674  1.25458            0.258065         0.511737                    0.0645161       0.879032                   -36.7326  25.4581\n",
       "    14       0.799342                    0.211909           0.245161  1.12996            0.1              0.460905                    0.0241935       0.903226                   -75.4839  12.9962\n",
       "    15       0.898026                    0.150747           0.735484  1.08661            0.3              0.443223                    0.0725806       0.975806                   -26.4516  8.66123\n",
       "    16       1                           0.0737707          0.237253  1                  0.0967742        0.407895                    0.0241935       1                          -76.2747  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.733527</td>\n",
       "<td>0.0451537</td>\n",
       "<td>0.6190476</td>\n",
       "<td>0.7222222</td>\n",
       "<td>0.7457627</td>\n",
       "<td>0.8070176</td>\n",
       "<td>0.7735849</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.7787671</td>\n",
       "<td>0.0350721</td>\n",
       "<td>0.7231237</td>\n",
       "<td>0.7370213</td>\n",
       "<td>0.8220238</td>\n",
       "<td>0.85125</td>\n",
       "<td>0.7604167</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.266473</td>\n",
       "<td>0.0451537</td>\n",
       "<td>0.3809524</td>\n",
       "<td>0.2777778</td>\n",
       "<td>0.2542373</td>\n",
       "<td>0.1929824</td>\n",
       "<td>0.2264151</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>16.4</td>\n",
       "<td>3.481379</td>\n",
       "<td>24.0</td>\n",
       "<td>20.0</td>\n",
       "<td>15.0</td>\n",
       "<td>11.0</td>\n",
       "<td>12.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.6679074</td>\n",
       "<td>0.0441851</td>\n",
       "<td>0.6008584</td>\n",
       "<td>0.6015037</td>\n",
       "<td>0.6730769</td>\n",
       "<td>0.7664233</td>\n",
       "<td>0.6976744</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.7189359</td>\n",
       "<td>0.0421566</td>\n",
       "<td>0.7</td>\n",
       "<td>0.6153846</td>\n",
       "<td>0.7368421</td>\n",
       "<td>0.7924528</td>\n",
       "<td>0.75</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.7826643</td>\n",
       "<td>0.0544215</td>\n",
       "<td>0.8383234</td>\n",
       "<td>0.6299213</td>\n",
       "<td>0.8139535</td>\n",
       "<td>0.8203125</td>\n",
       "<td>0.8108108</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.4629114</td>\n",
       "<td>0.1719122</td>\n",
       "<td>2.1724138</td>\n",
       "<td>2.88</td>\n",
       "<td>2.4583333</td>\n",
       "<td>2.28</td>\n",
       "<td>2.5238094</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.5729677</td>\n",
       "<td>0.0320329</td>\n",
       "<td>0.6447898</td>\n",
       "<td>0.6022099</td>\n",
       "<td>0.5239149</td>\n",
       "<td>0.5313293</td>\n",
       "<td>0.5625943</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.3758655</td>\n",
       "<td>0.1119563</td>\n",
       "<td>0.6764706</td>\n",
       "<td>0.36</td>\n",
       "<td>0.3428571</td>\n",
       "<td>0.21875</td>\n",
       "<td>0.28125</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.4945463</td>\n",
       "<td>0.0678699</td>\n",
       "<td>0.3668856</td>\n",
       "<td>0.3992191</td>\n",
       "<td>0.5265313</td>\n",
       "<td>0.6166424</td>\n",
       "<td>0.5634531</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.7424290</td>\n",
       "<td>0.0429224</td>\n",
       "<td>0.6445233</td>\n",
       "<td>0.7029787</td>\n",
       "<td>0.7660714</td>\n",
       "<td>0.810625</td>\n",
       "<td>0.7879464</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.257571</td>\n",
       "<td>0.0429224</td>\n",
       "<td>0.3554767</td>\n",
       "<td>0.2970213</td>\n",
       "<td>0.2339286</td>\n",
       "<td>0.189375</td>\n",
       "<td>0.2120536</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.1936592</td>\n",
       "<td>0.0132610</td>\n",
       "<td>0.2228830</td>\n",
       "<td>0.2066731</td>\n",
       "<td>0.1749692</td>\n",
       "<td>0.1745171</td>\n",
       "<td>0.1892535</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.6389285</td>\n",
       "<td>0.0483151</td>\n",
       "<td>0.5490196</td>\n",
       "<td>0.5925926</td>\n",
       "<td>0.6363636</td>\n",
       "<td>0.75</td>\n",
       "<td>0.6666667</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.1932127</td>\n",
       "<td>0.0597798</td>\n",
       "<td>0.1028170</td>\n",
       "<td>0.0881761</td>\n",
       "<td>0.2749194</td>\n",
       "<td>0.2912423</td>\n",
       "<td>0.2089089</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.835532</td>\n",
       "<td>0.0756133</td>\n",
       "<td>0.9655172</td>\n",
       "<td>0.64</td>\n",
       "<td>0.875</td>\n",
       "<td>0.84</td>\n",
       "<td>0.8571429</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.4395593</td>\n",
       "<td>0.0149469</td>\n",
       "<td>0.4721048</td>\n",
       "<td>0.4546131</td>\n",
       "<td>0.4182932</td>\n",
       "<td>0.4177525</td>\n",
       "<td>0.4350328</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.6493260</td>\n",
       "<td>0.1191768</td>\n",
       "<td>0.3235294</td>\n",
       "<td>0.7659575</td>\n",
       "<td>0.6571429</td>\n",
       "<td>0.78125</td>\n",
       "<td>0.71875</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean      sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  --------  ---------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.733527  0.0451537  0.619048      0.722222      0.745763      0.807018      0.773585\n",
       "auc                      0.778767  0.0350721  0.723124      0.737021      0.822024      0.85125       0.760417\n",
       "err                      0.266473  0.0451537  0.380952      0.277778      0.254237      0.192982      0.226415\n",
       "err_count                16.4      3.48138    24            20            15            11            12\n",
       "f0point5                 0.667907  0.0441851  0.600858      0.601504      0.673077      0.766423      0.697674\n",
       "f1                       0.718936  0.0421566  0.7           0.615385      0.736842      0.792453      0.75\n",
       "f2                       0.782664  0.0544215  0.838323      0.629921      0.813953      0.820312      0.810811\n",
       "lift_top_group           2.46291   0.171912   2.17241       2.88          2.45833       2.28          2.52381\n",
       "logloss                  0.572968  0.0320329  0.64479       0.60221       0.523915      0.531329      0.562594\n",
       "max_per_class_error      0.375866  0.111956   0.676471      0.36          0.342857      0.21875       0.28125\n",
       "mcc                      0.494546  0.0678699  0.366886      0.399219      0.526531      0.616642      0.563453\n",
       "mean_per_class_accuracy  0.742429  0.0429224  0.644523      0.702979      0.766071      0.810625      0.787946\n",
       "mean_per_class_error     0.257571  0.0429224  0.355477      0.297021      0.233929      0.189375      0.212054\n",
       "mse                      0.193659  0.013261   0.222883      0.206673      0.174969      0.174517      0.189254\n",
       "precision                0.638929  0.0483151  0.54902       0.592593      0.636364      0.75          0.666667\n",
       "r2                       0.193213  0.0597798  0.102817      0.0881761     0.274919      0.291242      0.208909\n",
       "recall                   0.835532  0.0756133  0.965517      0.64          0.875         0.84          0.857143\n",
       "rmse                     0.439559  0.0149469  0.472105      0.454613      0.418293      0.417752      0.435033\n",
       "specificity              0.649326  0.119177   0.323529      0.765957      0.657143      0.78125       0.71875"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:28:12</td>\n",
       "<td> 0.066 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4914434</td>\n",
       "<td>0.6760831</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5921053</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:28:12</td>\n",
       "<td> 0.068 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4641092</td>\n",
       "<td>0.6223024</td>\n",
       "<td>0.7991039</td>\n",
       "<td>2.0302419</td>\n",
       "<td>0.2828947</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:28:12</td>\n",
       "<td> 0.070 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.4421353</td>\n",
       "<td>0.5804965</td>\n",
       "<td>0.8329525</td>\n",
       "<td>2.1792115</td>\n",
       "<td>0.2368421</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:28:12</td>\n",
       "<td> 0.071 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.4251624</td>\n",
       "<td>0.5486142</td>\n",
       "<td>0.8558916</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.2105263</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:28:12</td>\n",
       "<td> 0.073 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.4100590</td>\n",
       "<td>0.5200064</td>\n",
       "<td>0.8734991</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.2039474</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:28:12</td>\n",
       "<td> 0.075 sec</td>\n",
       "<td>5.0</td>\n",
       "<td>0.3993799</td>\n",
       "<td>0.4997344</td>\n",
       "<td>0.8776658</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.1842105</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:28:12</td>\n",
       "<td> 0.076 sec</td>\n",
       "<td>6.0</td>\n",
       "<td>0.3900716</td>\n",
       "<td>0.4816657</td>\n",
       "<td>0.8864471</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.1776316</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:28:12</td>\n",
       "<td> 0.078 sec</td>\n",
       "<td>7.0</td>\n",
       "<td>0.3827618</td>\n",
       "<td>0.4675620</td>\n",
       "<td>0.8928315</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.1743421</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:28:12</td>\n",
       "<td> 0.080 sec</td>\n",
       "<td>8.0</td>\n",
       "<td>0.3750932</td>\n",
       "<td>0.4532488</td>\n",
       "<td>0.8986111</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.1677632</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:28:12</td>\n",
       "<td> 0.082 sec</td>\n",
       "<td>9.0</td>\n",
       "<td>0.3675625</td>\n",
       "<td>0.4388515</td>\n",
       "<td>0.9108647</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.1677632</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:28:12</td>\n",
       "<td> 0.084 sec</td>\n",
       "<td>10.0</td>\n",
       "<td>0.3614020</td>\n",
       "<td>0.4269081</td>\n",
       "<td>0.9161290</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.1414474</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_lift    training_classification_error\n",
       "--  -------------------  ----------  -----------------  ---------------  ------------------  --------------  ---------------  -------------------------------\n",
       "    2017-11-13 22:28:12  0.066 sec   0                  0.491443         0.676083            0.5             1                0.592105\n",
       "    2017-11-13 22:28:12  0.068 sec   1                  0.464109         0.622302            0.799104        2.03024          0.282895\n",
       "    2017-11-13 22:28:12  0.070 sec   2                  0.442135         0.580496            0.832953        2.17921          0.236842\n",
       "    2017-11-13 22:28:12  0.071 sec   3                  0.425162         0.548614            0.855892        2.45161          0.210526\n",
       "    2017-11-13 22:28:12  0.073 sec   4                  0.410059         0.520006            0.873499        2.45161          0.203947\n",
       "    2017-11-13 22:28:12  0.075 sec   5                  0.39938          0.499734            0.877666        2.45161          0.184211\n",
       "    2017-11-13 22:28:12  0.076 sec   6                  0.390072         0.481666            0.886447        2.45161          0.177632\n",
       "    2017-11-13 22:28:12  0.078 sec   7                  0.382762         0.467562            0.892832        2.45161          0.174342\n",
       "    2017-11-13 22:28:12  0.080 sec   8                  0.375093         0.453249            0.898611        2.45161          0.167763\n",
       "    2017-11-13 22:28:12  0.082 sec   9                  0.367563         0.438852            0.910865        2.45161          0.167763\n",
       "    2017-11-13 22:28:12  0.084 sec   10                 0.361402         0.426908            0.916129        2.45161          0.141447"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>GLEASON</td>\n",
       "<td>31.3430843</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3299015</td></tr>\n",
       "<tr><td>PSA</td>\n",
       "<td>21.4544888</td>\n",
       "<td>0.6845047</td>\n",
       "<td>0.2258191</td></tr>\n",
       "<tr><td>ID</td>\n",
       "<td>17.0306625</td>\n",
       "<td>0.5433627</td>\n",
       "<td>0.1792561</td></tr>\n",
       "<tr><td>DPROS</td>\n",
       "<td>11.3770695</td>\n",
       "<td>0.3629850</td>\n",
       "<td>0.1197493</td></tr>\n",
       "<tr><td>VOL</td>\n",
       "<td>8.5292339</td>\n",
       "<td>0.2721249</td>\n",
       "<td>0.0897744</td></tr>\n",
       "<tr><td>AGE</td>\n",
       "<td>2.9414146</td>\n",
       "<td>0.0938457</td>\n",
       "<td>0.0309598</td></tr>\n",
       "<tr><td>DCAPS</td>\n",
       "<td>2.3314576</td>\n",
       "<td>0.0743851</td>\n",
       "<td>0.0245397</td></tr>\n",
       "<tr><td>RACE</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  ------------\n",
       "GLEASON     31.3431                1                    0.329901\n",
       "PSA         21.4545                0.684505             0.225819\n",
       "ID          17.0307                0.543363             0.179256\n",
       "DPROS       11.3771                0.362985             0.119749\n",
       "VOL         8.52923                0.272125             0.0897744\n",
       "AGE         2.94141                0.0938457            0.0309598\n",
       "DCAPS       2.33146                0.0743851            0.0245397\n",
       "RACE        0                      0                    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model_with_training_cv_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Performing predictions with one of the above model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_predictions = gbm_model_with_training_cv_config.predict(df_gbm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">      p0</th><th style=\"text-align: right;\">      p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.574046</td><td style=\"text-align: right;\">0.425954</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.273641</td><td style=\"text-align: right;\">0.726359</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.897923</td><td style=\"text-align: right;\">0.102077</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.877937</td><td style=\"text-align: right;\">0.122063</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.392107</td><td style=\"text-align: right;\">0.607893</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.815632</td><td style=\"text-align: right;\">0.184368</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.175125</td><td style=\"text-align: right;\">0.824875</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.857432</td><td style=\"text-align: right;\">0.142568</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.33968 </td><td style=\"text-align: right;\">0.66032 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.835209</td><td style=\"text-align: right;\">0.164791</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Understanding/Validating predictions based on prediction results historgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "h2o.frame.H2OFrame"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gbm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Here we can select the best model based on accuracy among all of above models we have created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0637863025683\n",
      "RMSE: 0.252559503025\n",
      "LogLoss: 0.244491796997\n",
      "Mean Per-Class Error: 0.0581900895454\n",
      "AUC: 0.98825256975\n",
      "Gini: 0.976505139501\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.369290229047: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>208.0</td>\n",
       "<td>19.0</td>\n",
       "<td>0.0837</td>\n",
       "<td> (19.0/227.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>5.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0327</td>\n",
       "<td> (5.0/153.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>213.0</td>\n",
       "<td>167.0</td>\n",
       "<td>0.0632</td>\n",
       "<td> (24.0/380.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      208  19   0.0837   (19.0/227.0)\n",
       "1      5    148  0.0327   (5.0/153.0)\n",
       "Total  213  167  0.0632   (24.0/380.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3692902</td>\n",
       "<td>0.925</td>\n",
       "<td>166.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3284870</td>\n",
       "<td>0.9554140</td>\n",
       "<td>172.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5709882</td>\n",
       "<td>0.9471366</td>\n",
       "<td>131.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4617671</td>\n",
       "<td>0.9368421</td>\n",
       "<td>150.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9740913</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.2716047</td>\n",
       "<td>1.0</td>\n",
       "<td>200.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9740913</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3692902</td>\n",
       "<td>0.8731243</td>\n",
       "<td>166.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4303894</td>\n",
       "<td>0.9295154</td>\n",
       "<td>158.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3692902</td>\n",
       "<td>0.9418099</td>\n",
       "<td>166.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.36929      0.925     166\n",
       "max f2                       0.328487     0.955414  172\n",
       "max f0point5                 0.570988     0.947137  131\n",
       "max accuracy                 0.461767     0.936842  150\n",
       "max precision                0.974091     1         0\n",
       "max recall                   0.271605     1         200\n",
       "max specificity              0.974091     1         0\n",
       "max absolute_mcc             0.36929      0.873124  166\n",
       "max min_per_class_accuracy   0.430389     0.929515  158\n",
       "max mean_per_class_accuracy  0.36929      0.94181   166"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 40.26 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0105263</td>\n",
       "<td>0.9656726</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0261438</td>\n",
       "<td>0.0261438</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0210526</td>\n",
       "<td>0.9589343</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0261438</td>\n",
       "<td>0.0522876</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0315789</td>\n",
       "<td>0.9507825</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0261438</td>\n",
       "<td>0.0784314</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0421053</td>\n",
       "<td>0.9422672</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0261438</td>\n",
       "<td>0.1045752</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.9301226</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0196078</td>\n",
       "<td>0.1241830</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.9044146</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1241830</td>\n",
       "<td>0.2483660</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.8446853</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1241830</td>\n",
       "<td>0.3725490</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.7961432</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1241830</td>\n",
       "<td>0.4967320</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.6723258</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2483660</td>\n",
       "<td>0.7450980</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.4587689</td>\n",
       "<td>1.6993464</td>\n",
       "<td>2.2875817</td>\n",
       "<td>0.6842105</td>\n",
       "<td>0.9210526</td>\n",
       "<td>0.1699346</td>\n",
       "<td>0.9150327</td>\n",
       "<td>69.9346405</td>\n",
       "<td>128.7581699</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.2941654</td>\n",
       "<td>0.7843137</td>\n",
       "<td>1.9869281</td>\n",
       "<td>0.3157895</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0784314</td>\n",
       "<td>0.9934641</td>\n",
       "<td>-21.5686275</td>\n",
       "<td>98.6928105</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.1936958</td>\n",
       "<td>0.0653595</td>\n",
       "<td>1.6666667</td>\n",
       "<td>0.0263158</td>\n",
       "<td>0.6710526</td>\n",
       "<td>0.0065359</td>\n",
       "<td>1.0</td>\n",
       "<td>-93.4640523</td>\n",
       "<td>66.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.1169011</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285714</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5751880</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0800475</td>\n",
       "<td>0.0</td>\n",
       "<td>1.25</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5032895</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0473553</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111111</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4473684</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0097484</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4026316</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0105263                   0.965673           2.48366    2.48366            1                1                           0.0261438       0.0261438                  148.366   148.366\n",
       "    2        0.0210526                   0.958934           2.48366    2.48366            1                1                           0.0261438       0.0522876                  148.366   148.366\n",
       "    3        0.0315789                   0.950783           2.48366    2.48366            1                1                           0.0261438       0.0784314                  148.366   148.366\n",
       "    4        0.0421053                   0.942267           2.48366    2.48366            1                1                           0.0261438       0.104575                   148.366   148.366\n",
       "    5        0.05                        0.930123           2.48366    2.48366            1                1                           0.0196078       0.124183                   148.366   148.366\n",
       "    6        0.1                         0.904415           2.48366    2.48366            1                1                           0.124183        0.248366                   148.366   148.366\n",
       "    7        0.15                        0.844685           2.48366    2.48366            1                1                           0.124183        0.372549                   148.366   148.366\n",
       "    8        0.2                         0.796143           2.48366    2.48366            1                1                           0.124183        0.496732                   148.366   148.366\n",
       "    9        0.3                         0.672326           2.48366    2.48366            1                1                           0.248366        0.745098                   148.366   148.366\n",
       "    10       0.4                         0.458769           1.69935    2.28758            0.684211         0.921053                    0.169935        0.915033                   69.9346   128.758\n",
       "    11       0.5                         0.294165           0.784314   1.98693            0.315789         0.8                         0.0784314       0.993464                   -21.5686  98.6928\n",
       "    12       0.6                         0.193696           0.0653595  1.66667            0.0263158        0.671053                    0.00653595      1                          -93.4641  66.6667\n",
       "    13       0.7                         0.116901           0          1.42857            0                0.575188                    0               1                          -100      42.8571\n",
       "    14       0.8                         0.0800475          0          1.25               0                0.503289                    0               1                          -100      25\n",
       "    15       0.9                         0.0473553          0          1.11111            0                0.447368                    0               1                          -100      11.1111\n",
       "    16       1                           0.00974841         0          1                  0                0.402632                    0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model_with_training_and_cv.model_performance(train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Here we can select the best model based on accuracy among all of above models we have created \n",
    "#: AUC Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9882525697503671"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model_with_training_and_cv.model_performance(train=True).auc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: RMSE (Root Mean Square) Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.252559503025\n",
      "0.439828921204\n"
     ]
    }
   ],
   "source": [
    "print(gbm_model_with_training_and_cv.model_performance(train=True).rmse())\n",
    "print(gbm_model_with_training_and_cv.model_performance(xval=True).rmse())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: AUC (Area Under Curve) Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.98825256975\n",
      "0.771385793671\n"
     ]
    }
   ],
   "source": [
    "print(gbm_model_with_training_and_cv.model_performance(train=True).auc())\n",
    "print(gbm_model_with_training_and_cv.model_performance(xval=True).auc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: R^2 (R^2) Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.773051074251\n",
      "0.321294545324\n"
     ]
    }
   ],
   "source": [
    "print(gbm_model_with_training_and_validtion.model_performance(train=True).r2())\n",
    "print(gbm_model_with_training_and_validtion.model_performance(valid=True).r2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Getting model ID from an H2O Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBM_model_python_1510608322538_214\n",
      "glm_model_with_training_and_validtion_python\n"
     ]
    }
   ],
   "source": [
    "print(gbm_model_with_training_and_cv.model_id)\n",
    "print(gbm_model_with_training_and_validtion.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Because we have built the GBM model, getting coefficients from the model will give error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "u'coefficients_table'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-df257a71f863>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## coefficients >>> GBM model does not have coefficients to display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgbm_model_with_training_and_validtion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/avkashchauhan/anaconda3/envs/python27/lib/python2.7/site-packages/h2o/model/model_base.pyc\u001b[0m in \u001b[0;36mcoef\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0mNote\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstandardize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m \u001b[0mby\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m \u001b[0mto\u001b[0m \u001b[0mFalse\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcoefficients\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mare\u001b[0m \u001b[0mfit\u001b[0m \u001b[0mdirectly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \"\"\"\n\u001b[0;32m--> 456\u001b[0;31m         \u001b[0mtbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"coefficients_table\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtbl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: u'coefficients_table'"
     ]
    }
   ],
   "source": [
    "## coefficients >>> GBM model does not have coefficients to display\n",
    "gbm_model_with_training_and_validtion.coef()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Because we have built the GBM model, getting coefficients from the model will give error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "u'coefficients_table'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-62405970672a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgbm_model_with_training_and_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## >>> GBM models does not have coeffiecients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/avkashchauhan/anaconda3/envs/python27/lib/python2.7/site-packages/h2o/model/model_base.pyc\u001b[0m in \u001b[0;36mcoef_norm\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0mThese\u001b[0m \u001b[0mcoefficients\u001b[0m \u001b[0mcan\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m \u001b[0mto\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0mimportance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \"\"\"\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0mtbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"coefficients_table\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtbl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: u'coefficients_table'"
     ]
    }
   ],
   "source": [
    "gbm_model_with_training_and_cv.coef_norm() ## >>> GBM models does not have coeffiecients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Getting Scorring History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration</th>\n",
       "      <th>number_of_trees</th>\n",
       "      <th>training_rmse</th>\n",
       "      <th>training_logloss</th>\n",
       "      <th>training_auc</th>\n",
       "      <th>training_lift</th>\n",
       "      <th>training_classification_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.694 sec</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.490428</td>\n",
       "      <td>0.674064</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.597368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.698 sec</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.468619</td>\n",
       "      <td>0.630723</td>\n",
       "      <td>0.889306</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.205263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.702 sec</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.451185</td>\n",
       "      <td>0.597276</td>\n",
       "      <td>0.896879</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.186842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.705 sec</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.436452</td>\n",
       "      <td>0.569531</td>\n",
       "      <td>0.898981</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.181579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.708 sec</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.423506</td>\n",
       "      <td>0.545449</td>\n",
       "      <td>0.903184</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.168421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.712 sec</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.412446</td>\n",
       "      <td>0.524774</td>\n",
       "      <td>0.903055</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.181579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.715 sec</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.402357</td>\n",
       "      <td>0.506156</td>\n",
       "      <td>0.913391</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.719 sec</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.394077</td>\n",
       "      <td>0.490678</td>\n",
       "      <td>0.918646</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.186842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.723 sec</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.385064</td>\n",
       "      <td>0.474123</td>\n",
       "      <td>0.927068</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.173684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.727 sec</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.376159</td>\n",
       "      <td>0.457907</td>\n",
       "      <td>0.931646</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.165789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.731 sec</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.368922</td>\n",
       "      <td>0.444259</td>\n",
       "      <td>0.934871</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.160526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.735 sec</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.362445</td>\n",
       "      <td>0.432459</td>\n",
       "      <td>0.938585</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.160526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.740 sec</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.355742</td>\n",
       "      <td>0.420255</td>\n",
       "      <td>0.942803</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.152632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.745 sec</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.350617</td>\n",
       "      <td>0.410604</td>\n",
       "      <td>0.944675</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.142105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.749 sec</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.344536</td>\n",
       "      <td>0.399595</td>\n",
       "      <td>0.947525</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.136842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.754 sec</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.340255</td>\n",
       "      <td>0.391244</td>\n",
       "      <td>0.948634</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.136842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.759 sec</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.336382</td>\n",
       "      <td>0.383989</td>\n",
       "      <td>0.951484</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.136842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.763 sec</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.333028</td>\n",
       "      <td>0.377413</td>\n",
       "      <td>0.951312</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.142105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.766 sec</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.330159</td>\n",
       "      <td>0.372033</td>\n",
       "      <td>0.952881</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.134211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.772 sec</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.327789</td>\n",
       "      <td>0.367373</td>\n",
       "      <td>0.953716</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.131579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.777 sec</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.322999</td>\n",
       "      <td>0.359178</td>\n",
       "      <td>0.957761</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.113158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.782 sec</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.320026</td>\n",
       "      <td>0.353590</td>\n",
       "      <td>0.959345</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.787 sec</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.316641</td>\n",
       "      <td>0.347453</td>\n",
       "      <td>0.960871</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.792 sec</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.314902</td>\n",
       "      <td>0.344077</td>\n",
       "      <td>0.961418</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.102632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.797 sec</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.313045</td>\n",
       "      <td>0.340362</td>\n",
       "      <td>0.962181</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.097368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.804 sec</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.309266</td>\n",
       "      <td>0.334013</td>\n",
       "      <td>0.963678</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.094737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.809 sec</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.305988</td>\n",
       "      <td>0.328457</td>\n",
       "      <td>0.965233</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.089474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.815 sec</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.302950</td>\n",
       "      <td>0.323253</td>\n",
       "      <td>0.966960</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.092105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.820 sec</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.298426</td>\n",
       "      <td>0.316206</td>\n",
       "      <td>0.969278</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.086842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.827 sec</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.296449</td>\n",
       "      <td>0.312581</td>\n",
       "      <td>0.970286</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.084211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.832 sec</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.294526</td>\n",
       "      <td>0.309215</td>\n",
       "      <td>0.970775</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.084211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.839 sec</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.292988</td>\n",
       "      <td>0.306363</td>\n",
       "      <td>0.970919</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.084211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.845 sec</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.291393</td>\n",
       "      <td>0.303477</td>\n",
       "      <td>0.971610</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.086842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.851 sec</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.289369</td>\n",
       "      <td>0.299864</td>\n",
       "      <td>0.972157</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.084211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.858 sec</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.285651</td>\n",
       "      <td>0.294678</td>\n",
       "      <td>0.974922</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.081579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.865 sec</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.283345</td>\n",
       "      <td>0.290926</td>\n",
       "      <td>0.975757</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.081579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.872 sec</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.281950</td>\n",
       "      <td>0.288590</td>\n",
       "      <td>0.976793</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.078947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.879 sec</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.279655</td>\n",
       "      <td>0.284913</td>\n",
       "      <td>0.978319</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.076316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.885 sec</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.278224</td>\n",
       "      <td>0.282363</td>\n",
       "      <td>0.978463</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.078947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.891 sec</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.276348</td>\n",
       "      <td>0.279365</td>\n",
       "      <td>0.979068</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.073684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.897 sec</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.273998</td>\n",
       "      <td>0.275829</td>\n",
       "      <td>0.979931</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.078947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.903 sec</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.270309</td>\n",
       "      <td>0.270755</td>\n",
       "      <td>0.981659</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.078947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.908 sec</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.268199</td>\n",
       "      <td>0.267596</td>\n",
       "      <td>0.982494</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.073684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.913 sec</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.265955</td>\n",
       "      <td>0.264269</td>\n",
       "      <td>0.983588</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.068421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.918 sec</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.264132</td>\n",
       "      <td>0.261568</td>\n",
       "      <td>0.984078</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.068421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.924 sec</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.262276</td>\n",
       "      <td>0.258877</td>\n",
       "      <td>0.985460</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.071053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.929 sec</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.260798</td>\n",
       "      <td>0.256652</td>\n",
       "      <td>0.985776</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.063158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.934 sec</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.257917</td>\n",
       "      <td>0.252392</td>\n",
       "      <td>0.986669</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.065789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.940 sec</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.257058</td>\n",
       "      <td>0.250890</td>\n",
       "      <td>0.986698</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.063158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.946 sec</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.253522</td>\n",
       "      <td>0.245915</td>\n",
       "      <td>0.988051</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.063158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td></td>\n",
       "      <td>2017-11-13 22:26:47</td>\n",
       "      <td>0.951 sec</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.252560</td>\n",
       "      <td>0.244492</td>\n",
       "      <td>0.988253</td>\n",
       "      <td>2.48366</td>\n",
       "      <td>0.063158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp    duration  number_of_trees  training_rmse  \\\n",
       "0     2017-11-13 22:26:47   0.694 sec              0.0       0.490428   \n",
       "1     2017-11-13 22:26:47   0.698 sec              1.0       0.468619   \n",
       "2     2017-11-13 22:26:47   0.702 sec              2.0       0.451185   \n",
       "3     2017-11-13 22:26:47   0.705 sec              3.0       0.436452   \n",
       "4     2017-11-13 22:26:47   0.708 sec              4.0       0.423506   \n",
       "5     2017-11-13 22:26:47   0.712 sec              5.0       0.412446   \n",
       "6     2017-11-13 22:26:47   0.715 sec              6.0       0.402357   \n",
       "7     2017-11-13 22:26:47   0.719 sec              7.0       0.394077   \n",
       "8     2017-11-13 22:26:47   0.723 sec              8.0       0.385064   \n",
       "9     2017-11-13 22:26:47   0.727 sec              9.0       0.376159   \n",
       "10    2017-11-13 22:26:47   0.731 sec             10.0       0.368922   \n",
       "11    2017-11-13 22:26:47   0.735 sec             11.0       0.362445   \n",
       "12    2017-11-13 22:26:47   0.740 sec             12.0       0.355742   \n",
       "13    2017-11-13 22:26:47   0.745 sec             13.0       0.350617   \n",
       "14    2017-11-13 22:26:47   0.749 sec             14.0       0.344536   \n",
       "15    2017-11-13 22:26:47   0.754 sec             15.0       0.340255   \n",
       "16    2017-11-13 22:26:47   0.759 sec             16.0       0.336382   \n",
       "17    2017-11-13 22:26:47   0.763 sec             17.0       0.333028   \n",
       "18    2017-11-13 22:26:47   0.766 sec             18.0       0.330159   \n",
       "19    2017-11-13 22:26:47   0.772 sec             19.0       0.327789   \n",
       "20    2017-11-13 22:26:47   0.777 sec             20.0       0.322999   \n",
       "21    2017-11-13 22:26:47   0.782 sec             21.0       0.320026   \n",
       "22    2017-11-13 22:26:47   0.787 sec             22.0       0.316641   \n",
       "23    2017-11-13 22:26:47   0.792 sec             23.0       0.314902   \n",
       "24    2017-11-13 22:26:47   0.797 sec             24.0       0.313045   \n",
       "25    2017-11-13 22:26:47   0.804 sec             25.0       0.309266   \n",
       "26    2017-11-13 22:26:47   0.809 sec             26.0       0.305988   \n",
       "27    2017-11-13 22:26:47   0.815 sec             27.0       0.302950   \n",
       "28    2017-11-13 22:26:47   0.820 sec             28.0       0.298426   \n",
       "29    2017-11-13 22:26:47   0.827 sec             29.0       0.296449   \n",
       "30    2017-11-13 22:26:47   0.832 sec             30.0       0.294526   \n",
       "31    2017-11-13 22:26:47   0.839 sec             31.0       0.292988   \n",
       "32    2017-11-13 22:26:47   0.845 sec             32.0       0.291393   \n",
       "33    2017-11-13 22:26:47   0.851 sec             33.0       0.289369   \n",
       "34    2017-11-13 22:26:47   0.858 sec             34.0       0.285651   \n",
       "35    2017-11-13 22:26:47   0.865 sec             35.0       0.283345   \n",
       "36    2017-11-13 22:26:47   0.872 sec             36.0       0.281950   \n",
       "37    2017-11-13 22:26:47   0.879 sec             37.0       0.279655   \n",
       "38    2017-11-13 22:26:47   0.885 sec             38.0       0.278224   \n",
       "39    2017-11-13 22:26:47   0.891 sec             39.0       0.276348   \n",
       "40    2017-11-13 22:26:47   0.897 sec             40.0       0.273998   \n",
       "41    2017-11-13 22:26:47   0.903 sec             41.0       0.270309   \n",
       "42    2017-11-13 22:26:47   0.908 sec             42.0       0.268199   \n",
       "43    2017-11-13 22:26:47   0.913 sec             43.0       0.265955   \n",
       "44    2017-11-13 22:26:47   0.918 sec             44.0       0.264132   \n",
       "45    2017-11-13 22:26:47   0.924 sec             45.0       0.262276   \n",
       "46    2017-11-13 22:26:47   0.929 sec             46.0       0.260798   \n",
       "47    2017-11-13 22:26:47   0.934 sec             47.0       0.257917   \n",
       "48    2017-11-13 22:26:47   0.940 sec             48.0       0.257058   \n",
       "49    2017-11-13 22:26:47   0.946 sec             49.0       0.253522   \n",
       "50    2017-11-13 22:26:47   0.951 sec             50.0       0.252560   \n",
       "\n",
       "    training_logloss  training_auc  training_lift  \\\n",
       "0           0.674064      0.500000        1.00000   \n",
       "1           0.630723      0.889306        2.48366   \n",
       "2           0.597276      0.896879        2.48366   \n",
       "3           0.569531      0.898981        2.48366   \n",
       "4           0.545449      0.903184        2.48366   \n",
       "5           0.524774      0.903055        2.48366   \n",
       "6           0.506156      0.913391        2.48366   \n",
       "7           0.490678      0.918646        2.48366   \n",
       "8           0.474123      0.927068        2.48366   \n",
       "9           0.457907      0.931646        2.48366   \n",
       "10          0.444259      0.934871        2.48366   \n",
       "11          0.432459      0.938585        2.48366   \n",
       "12          0.420255      0.942803        2.48366   \n",
       "13          0.410604      0.944675        2.48366   \n",
       "14          0.399595      0.947525        2.48366   \n",
       "15          0.391244      0.948634        2.48366   \n",
       "16          0.383989      0.951484        2.48366   \n",
       "17          0.377413      0.951312        2.48366   \n",
       "18          0.372033      0.952881        2.48366   \n",
       "19          0.367373      0.953716        2.48366   \n",
       "20          0.359178      0.957761        2.48366   \n",
       "21          0.353590      0.959345        2.48366   \n",
       "22          0.347453      0.960871        2.48366   \n",
       "23          0.344077      0.961418        2.48366   \n",
       "24          0.340362      0.962181        2.48366   \n",
       "25          0.334013      0.963678        2.48366   \n",
       "26          0.328457      0.965233        2.48366   \n",
       "27          0.323253      0.966960        2.48366   \n",
       "28          0.316206      0.969278        2.48366   \n",
       "29          0.312581      0.970286        2.48366   \n",
       "30          0.309215      0.970775        2.48366   \n",
       "31          0.306363      0.970919        2.48366   \n",
       "32          0.303477      0.971610        2.48366   \n",
       "33          0.299864      0.972157        2.48366   \n",
       "34          0.294678      0.974922        2.48366   \n",
       "35          0.290926      0.975757        2.48366   \n",
       "36          0.288590      0.976793        2.48366   \n",
       "37          0.284913      0.978319        2.48366   \n",
       "38          0.282363      0.978463        2.48366   \n",
       "39          0.279365      0.979068        2.48366   \n",
       "40          0.275829      0.979931        2.48366   \n",
       "41          0.270755      0.981659        2.48366   \n",
       "42          0.267596      0.982494        2.48366   \n",
       "43          0.264269      0.983588        2.48366   \n",
       "44          0.261568      0.984078        2.48366   \n",
       "45          0.258877      0.985460        2.48366   \n",
       "46          0.256652      0.985776        2.48366   \n",
       "47          0.252392      0.986669        2.48366   \n",
       "48          0.250890      0.986698        2.48366   \n",
       "49          0.245915      0.988051        2.48366   \n",
       "50          0.244492      0.988253        2.48366   \n",
       "\n",
       "    training_classification_error  \n",
       "0                        0.597368  \n",
       "1                        0.205263  \n",
       "2                        0.186842  \n",
       "3                        0.181579  \n",
       "4                        0.168421  \n",
       "5                        0.181579  \n",
       "6                        0.200000  \n",
       "7                        0.186842  \n",
       "8                        0.173684  \n",
       "9                        0.165789  \n",
       "10                       0.160526  \n",
       "11                       0.160526  \n",
       "12                       0.152632  \n",
       "13                       0.142105  \n",
       "14                       0.136842  \n",
       "15                       0.136842  \n",
       "16                       0.136842  \n",
       "17                       0.142105  \n",
       "18                       0.134211  \n",
       "19                       0.131579  \n",
       "20                       0.113158  \n",
       "21                       0.105263  \n",
       "22                       0.105263  \n",
       "23                       0.102632  \n",
       "24                       0.097368  \n",
       "25                       0.094737  \n",
       "26                       0.089474  \n",
       "27                       0.092105  \n",
       "28                       0.086842  \n",
       "29                       0.084211  \n",
       "30                       0.084211  \n",
       "31                       0.084211  \n",
       "32                       0.086842  \n",
       "33                       0.084211  \n",
       "34                       0.081579  \n",
       "35                       0.081579  \n",
       "36                       0.078947  \n",
       "37                       0.076316  \n",
       "38                       0.078947  \n",
       "39                       0.073684  \n",
       "40                       0.078947  \n",
       "41                       0.078947  \n",
       "42                       0.073684  \n",
       "43                       0.068421  \n",
       "44                       0.068421  \n",
       "45                       0.071053  \n",
       "46                       0.063158  \n",
       "47                       0.065789  \n",
       "48                       0.063158  \n",
       "49                       0.063158  \n",
       "50                       0.063158  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model_with_training_and_cv.score_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Getting GBM model variable importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'GLEASON', 110.32581329345703, 1.0, 0.32299868195890524),\n",
       " (u'ID', 58.69680404663086, 0.5320314647534252, 0.17184546187602212),\n",
       " (u'PSA', 57.76746368408203, 0.5236078661883563, 0.16912465064215393),\n",
       " (u'VOL', 40.088531494140625, 0.3633649306305917, 0.11736639366377016),\n",
       " (u'DPROS', 34.955631256103516, 0.3168400051864978, 0.10233890406709151),\n",
       " (u'AGE', 31.499591827392578, 0.28551424990275315, 0.09222072639907478),\n",
       " (u'DCAPS', 7.156589031219482, 0.06486776591606518, 0.020952202892507852),\n",
       " (u'RACE', 1.0769546031951904, 0.009761583178458745, 0.003152978500474396)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model_with_training_and_cv.varimp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Getting GBM model variable importance PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1UAAAJTCAYAAADg0TxvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wfraoGwkqd+cgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1142a7a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbm_model_with_training_and_cv.varimp_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Getting cross validation prediction details from the model with cross-validation \n",
    "#: (If cross validation prediction save is not set to TRUE, you will get error message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.7287913</td>\n",
       "<td>0.0403975</td>\n",
       "<td>0.71875</td>\n",
       "<td>0.7228916</td>\n",
       "<td>0.6375</td>\n",
       "<td>0.8148148</td>\n",
       "<td>0.75</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.7700940</td>\n",
       "<td>0.0343016</td>\n",
       "<td>0.7761486</td>\n",
       "<td>0.7654762</td>\n",
       "<td>0.74</td>\n",
       "<td>0.8565051</td>\n",
       "<td>0.7123404</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.2712087</td>\n",
       "<td>0.0403975</td>\n",
       "<td>0.28125</td>\n",
       "<td>0.2771084</td>\n",
       "<td>0.3625</td>\n",
       "<td>0.1851852</td>\n",
       "<td>0.25</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>20.6</td>\n",
       "<td>3.481379</td>\n",
       "<td>18.0</td>\n",
       "<td>23.0</td>\n",
       "<td>29.0</td>\n",
       "<td>15.0</td>\n",
       "<td>18.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.6605104</td>\n",
       "<td>0.0457309</td>\n",
       "<td>0.698324</td>\n",
       "<td>0.6595745</td>\n",
       "<td>0.5555556</td>\n",
       "<td>0.75</td>\n",
       "<td>0.6390978</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.7086272</td>\n",
       "<td>0.0374964</td>\n",
       "<td>0.7352941</td>\n",
       "<td>0.7294118</td>\n",
       "<td>0.6419753</td>\n",
       "<td>0.7826087</td>\n",
       "<td>0.6538461</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.7679788</td>\n",
       "<td>0.0383096</td>\n",
       "<td>0.7763975</td>\n",
       "<td>0.8157895</td>\n",
       "<td>0.7602339</td>\n",
       "<td>0.8181818</td>\n",
       "<td>0.6692913</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>2.5027723</td>\n",
       "<td>0.1947544</td>\n",
       "<td>2.064516</td>\n",
       "<td>2.3714285</td>\n",
       "<td>2.6666667</td>\n",
       "<td>2.53125</td>\n",
       "<td>2.88</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.5868385</td>\n",
       "<td>0.0469577</td>\n",
       "<td>0.6350344</td>\n",
       "<td>0.6178322</td>\n",
       "<td>0.5942904</td>\n",
       "<td>0.4570368</td>\n",
       "<td>0.6299987</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.3567103</td>\n",
       "<td>0.0683767</td>\n",
       "<td>0.3636364</td>\n",
       "<td>0.3958333</td>\n",
       "<td>0.5</td>\n",
       "<td>0.2040816</td>\n",
       "<td>0.32</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.4797853</td>\n",
       "<td>0.0597850</td>\n",
       "<td>0.4481028</td>\n",
       "<td>0.4943143</td>\n",
       "<td>0.3692606</td>\n",
       "<td>0.6277702</td>\n",
       "<td>0.4594786</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.7406265</td>\n",
       "<td>0.0316125</td>\n",
       "<td>0.7214076</td>\n",
       "<td>0.7449405</td>\n",
       "<td>0.6833333</td>\n",
       "<td>0.8198342</td>\n",
       "<td>0.733617</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.2593735</td>\n",
       "<td>0.0316125</td>\n",
       "<td>0.2785924</td>\n",
       "<td>0.2550595</td>\n",
       "<td>0.3166667</td>\n",
       "<td>0.1801658</td>\n",
       "<td>0.266383</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.1942187</td>\n",
       "<td>0.0162859</td>\n",
       "<td>0.2053715</td>\n",
       "<td>0.2031166</td>\n",
       "<td>0.2082852</td>\n",
       "<td>0.1482733</td>\n",
       "<td>0.2060471</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.6329678</td>\n",
       "<td>0.0515126</td>\n",
       "<td>0.6756757</td>\n",
       "<td>0.62</td>\n",
       "<td>0.5098040</td>\n",
       "<td>0.7297297</td>\n",
       "<td>0.6296296</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.1853289</td>\n",
       "<td>0.0724643</td>\n",
       "<td>0.1777110</td>\n",
       "<td>0.1671011</td>\n",
       "<td>0.1113163</td>\n",
       "<td>0.3795783</td>\n",
       "<td>0.0909377</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.8165165</td>\n",
       "<td>0.0517524</td>\n",
       "<td>0.8064516</td>\n",
       "<td>0.8857143</td>\n",
       "<td>0.8666667</td>\n",
       "<td>0.84375</td>\n",
       "<td>0.68</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.4398467</td>\n",
       "<td>0.0194116</td>\n",
       "<td>0.4531793</td>\n",
       "<td>0.4506846</td>\n",
       "<td>0.4563828</td>\n",
       "<td>0.3850627</td>\n",
       "<td>0.4539241</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.6647366</td>\n",
       "<td>0.0798913</td>\n",
       "<td>0.6363636</td>\n",
       "<td>0.6041667</td>\n",
       "<td>0.5</td>\n",
       "<td>0.7959183</td>\n",
       "<td>0.7872341</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean      sd         cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  --------  ---------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.728791  0.0403975  0.71875       0.722892      0.6375        0.814815      0.75\n",
       "auc                      0.770094  0.0343016  0.776149      0.765476      0.74          0.856505      0.71234\n",
       "err                      0.271209  0.0403975  0.28125       0.277108      0.3625        0.185185      0.25\n",
       "err_count                20.6      3.48138    18            23            29            15            18\n",
       "f0point5                 0.66051   0.0457309  0.698324      0.659574      0.555556      0.75          0.639098\n",
       "f1                       0.708627  0.0374964  0.735294      0.729412      0.641975      0.782609      0.653846\n",
       "f2                       0.767979  0.0383096  0.776397      0.815789      0.760234      0.818182      0.669291\n",
       "lift_top_group           2.50277   0.194754   2.06452       2.37143       2.66667       2.53125       2.88\n",
       "logloss                  0.586839  0.0469577  0.635034      0.617832      0.59429       0.457037      0.629999\n",
       "max_per_class_error      0.35671   0.0683767  0.363636      0.395833      0.5           0.204082      0.32\n",
       "mcc                      0.479785  0.059785   0.448103      0.494314      0.369261      0.62777       0.459479\n",
       "mean_per_class_accuracy  0.740626  0.0316125  0.721408      0.74494       0.683333      0.819834      0.733617\n",
       "mean_per_class_error     0.259373  0.0316125  0.278592      0.255059      0.316667      0.180166      0.266383\n",
       "mse                      0.194219  0.0162859  0.205372      0.203117      0.208285      0.148273      0.206047\n",
       "precision                0.632968  0.0515126  0.675676      0.62          0.509804      0.72973       0.62963\n",
       "r2                       0.185329  0.0724643  0.177711      0.167101      0.111316      0.379578      0.0909377\n",
       "recall                   0.816516  0.0517524  0.806452      0.885714      0.866667      0.84375       0.68\n",
       "rmse                     0.439847  0.0194116  0.453179      0.450685      0.456383      0.385063      0.453924\n",
       "specificity              0.664737  0.0798913  0.636364      0.604167      0.5           0.795918      0.787234"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model_with_training_and_cv.cross_validation_metrics_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Getting variable importance from a GBM mode (It will plot the coefficient table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'GLEASON', 73.4897232055664, 1.0, 0.2549634365179395),\n",
       " (u'PSA', 63.44717025756836, 0.8633475197626356, 0.22012205054792125),\n",
       " (u'ID', 57.41383361816406, 0.7812498280550785, 0.19919014093997214),\n",
       " (u'VOL', 50.6388053894043, 0.689059683185318, 0.17568502479089132),\n",
       " (u'DPROS', 24.522401809692383, 0.3336847757760361, 0.08507741714557626),\n",
       " (u'AGE', 15.411602973937988, 0.2097109949758343, 0.05346863595463505),\n",
       " (u'DCAPS', 3.1581649780273438, 0.04297423966604533, 0.010956859827000466),\n",
       " (u'RACE', 0.15461984276771545, 0.002103965507329655, 0.0005364342760639789)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model_with_training_and_validtion.varimp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Getting variable importance PLOT for GLM (Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1UAAAJTCAYAAADg0TxvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nh7sWKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b82d110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# - Positive ?\n",
    "# - Negative ?\n",
    "gbm_model_with_training_and_validtion.varimp_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Building a GBM model with cross validation and saving cross validation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "gbm_model_with_training_and_cv = H2OGradientBoostingEstimator(keep_cross_validation_predictions = True, nfolds=5)\n",
    "gbm_model_with_training_and_cv.train(x = features, y = response, training_frame= train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Looking at cross validation predictions for all CV models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gbm_model_with_training_and_cv.cross_validation_predictions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">      p0</th><th style=\"text-align: right;\">       p1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">0        </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">0        </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">0        </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">0        </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.970317</td><td style=\"text-align: right;\">0.0296829</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">0        </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">0        </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">0        </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">0        </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0       </td><td style=\"text-align: right;\">0        </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model_with_training_and_cv.cross_validation_predictions()[0]\n",
    "gbm_model_with_training_and_cv.cross_validation_predictions()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Accessing H2O Model details from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>number_of_internal_trees</b></td>\n",
       "<td><b>model_size_in_bytes</b></td>\n",
       "<td><b>min_depth</b></td>\n",
       "<td><b>max_depth</b></td>\n",
       "<td><b>mean_depth</b></td>\n",
       "<td><b>min_leaves</b></td>\n",
       "<td><b>max_leaves</b></td>\n",
       "<td><b>mean_leaves</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>50.0</td>\n",
       "<td>50.0</td>\n",
       "<td>11398.0</td>\n",
       "<td>5.0</td>\n",
       "<td>5.0</td>\n",
       "<td>5.0</td>\n",
       "<td>7.0</td>\n",
       "<td>20.0</td>\n",
       "<td>13.2</td></tr></table></div>"
      ],
      "text/plain": [
       "    number_of_trees    number_of_internal_trees    model_size_in_bytes    min_depth    max_depth    mean_depth    min_leaves    max_leaves    mean_leaves\n",
       "--  -----------------  --------------------------  ---------------------  -----------  -----------  ------------  ------------  ------------  -------------\n",
       "    50                 50                          11398                  5            5            5             7             20            13.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td>\n",
       "<td><b>validation_rmse</b></td>\n",
       "<td><b>validation_logloss</b></td>\n",
       "<td><b>validation_auc</b></td>\n",
       "<td><b>validation_lift</b></td>\n",
       "<td><b>validation_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:27:52</td>\n",
       "<td> 0.001 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4914434</td>\n",
       "<td>0.6760831</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.5921053</td>\n",
       "<td>0.4789546</td>\n",
       "<td>0.6515650</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6578947</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:27:52</td>\n",
       "<td> 0.005 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.4720114</td>\n",
       "<td>0.6374387</td>\n",
       "<td>0.8644041</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.2269737</td>\n",
       "<td>0.4650639</td>\n",
       "<td>0.6244840</td>\n",
       "<td>0.78</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.2368421</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:27:52</td>\n",
       "<td> 0.009 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.4554601</td>\n",
       "<td>0.6056158</td>\n",
       "<td>0.8869624</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.2171053</td>\n",
       "<td>0.4488147</td>\n",
       "<td>0.5937507</td>\n",
       "<td>0.8246154</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.2105263</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:27:52</td>\n",
       "<td> 0.013 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.4398059</td>\n",
       "<td>0.5760860</td>\n",
       "<td>0.8940412</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.2006579</td>\n",
       "<td>0.4337890</td>\n",
       "<td>0.5660393</td>\n",
       "<td>0.8446154</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.1315789</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:27:52</td>\n",
       "<td> 0.016 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.4278322</td>\n",
       "<td>0.5539058</td>\n",
       "<td>0.9040995</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.2039474</td>\n",
       "<td>0.4218901</td>\n",
       "<td>0.5441911</td>\n",
       "<td>0.8876923</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.1578947</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:27:52</td>\n",
       "<td> 0.224 sec</td>\n",
       "<td>46.0</td>\n",
       "<td>0.2413698</td>\n",
       "<td>0.2339888</td>\n",
       "<td>0.9938620</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.0394737</td>\n",
       "<td>0.3905465</td>\n",
       "<td>0.4824366</td>\n",
       "<td>0.8092308</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.2105263</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:27:52</td>\n",
       "<td> 0.230 sec</td>\n",
       "<td>47.0</td>\n",
       "<td>0.2398180</td>\n",
       "<td>0.2316915</td>\n",
       "<td>0.9942652</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.0361842</td>\n",
       "<td>0.3930096</td>\n",
       "<td>0.4865162</td>\n",
       "<td>0.8030769</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.2105263</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:27:52</td>\n",
       "<td> 0.236 sec</td>\n",
       "<td>48.0</td>\n",
       "<td>0.2385228</td>\n",
       "<td>0.2295585</td>\n",
       "<td>0.9940860</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.0361842</td>\n",
       "<td>0.3928504</td>\n",
       "<td>0.4853373</td>\n",
       "<td>0.8030769</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.2105263</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:27:52</td>\n",
       "<td> 0.242 sec</td>\n",
       "<td>49.0</td>\n",
       "<td>0.2372900</td>\n",
       "<td>0.2277650</td>\n",
       "<td>0.9944892</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.0361842</td>\n",
       "<td>0.3919804</td>\n",
       "<td>0.4835920</td>\n",
       "<td>0.8030769</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.2105263</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2017-11-13 22:27:52</td>\n",
       "<td> 0.249 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.2341195</td>\n",
       "<td>0.2235788</td>\n",
       "<td>0.9952061</td>\n",
       "<td>2.4516129</td>\n",
       "<td>0.0296053</td>\n",
       "<td>0.3908398</td>\n",
       "<td>0.4818136</td>\n",
       "<td>0.8092308</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.2105263</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_rmse    training_logloss    training_auc    training_lift    training_classification_error    validation_rmse    validation_logloss    validation_auc    validation_lift    validation_classification_error\n",
       "---  -------------------  ----------  -----------------  ---------------  ------------------  --------------  ---------------  -------------------------------  -----------------  --------------------  ----------------  -----------------  ---------------------------------\n",
       "     2017-11-13 22:27:52  0.001 sec   0.0                0.491443405184   0.676083137935      0.5             1.0              0.592105263158                   0.478954597979     0.651565027061        0.5               1.0                0.657894736842\n",
       "     2017-11-13 22:27:52  0.005 sec   1.0                0.47201136688    0.637438720533      0.864404121864  2.45161290323    0.226973684211                   0.465063859913     0.624484017531        0.78              2.92307692308      0.236842105263\n",
       "     2017-11-13 22:27:52  0.009 sec   2.0                0.455460131806   0.605615804428      0.886962365591  2.45161290323    0.217105263158                   0.448814670909     0.593750720034        0.824615384615    2.92307692308      0.210526315789\n",
       "     2017-11-13 22:27:52  0.013 sec   3.0                0.439805946936   0.576086017264      0.894041218638  2.45161290323    0.200657894737                   0.433788981793     0.566039257654        0.844615384615    2.92307692308      0.131578947368\n",
       "     2017-11-13 22:27:52  0.016 sec   4.0                0.427832214847   0.553905780061      0.904099462366  2.45161290323    0.203947368421                   0.421890125192     0.544191076593        0.887692307692    2.92307692308      0.157894736842\n",
       "---  ---                  ---         ---                ---              ---                 ---             ---              ---                              ---                ---                   ---               ---                ---\n",
       "     2017-11-13 22:27:52  0.224 sec   46.0               0.24136978177    0.233988756403      0.993862007168  2.45161290323    0.0394736842105                  0.39054650576      0.482436576318        0.809230769231    2.92307692308      0.210526315789\n",
       "     2017-11-13 22:27:52  0.230 sec   47.0               0.239818029435   0.231691518327      0.994265232975  2.45161290323    0.0361842105263                  0.393009617091     0.48651623121         0.803076923077    2.92307692308      0.210526315789\n",
       "     2017-11-13 22:27:52  0.236 sec   48.0               0.238522751147   0.229558475537      0.994086021505  2.45161290323    0.0361842105263                  0.39285041543      0.485337276163        0.803076923077    2.92307692308      0.210526315789\n",
       "     2017-11-13 22:27:52  0.242 sec   49.0               0.237290047562   0.22776499544       0.994489247312  2.45161290323    0.0361842105263                  0.391980378229     0.483591964311        0.803076923077    2.92307692308      0.210526315789\n",
       "     2017-11-13 22:27:52  0.249 sec   50.0               0.234119494217   0.223578775628      0.99520609319   2.45161290323    0.0296052631579                  0.390839774159     0.481813619133        0.809230769231    2.92307692308      0.210526315789"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0548119375726\n",
      "RMSE: 0.234119494217\n",
      "LogLoss: 0.223578775628\n",
      "Mean Per-Class Error: 0.030017921147\n",
      "AUC: 0.99520609319\n",
      "Gini: 0.99041218638\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.433295291885: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>175.0</td>\n",
       "<td>5.0</td>\n",
       "<td>0.0278</td>\n",
       "<td> (5.0/180.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>4.0</td>\n",
       "<td>120.0</td>\n",
       "<td>0.0323</td>\n",
       "<td> (4.0/124.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>179.0</td>\n",
       "<td>125.0</td>\n",
       "<td>0.0296</td>\n",
       "<td> (9.0/304.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  -----------\n",
       "0      175  5    0.0278   (5.0/180.0)\n",
       "1      4    120  0.0323   (4.0/124.0)\n",
       "Total  179  125  0.0296   (9.0/304.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4332953</td>\n",
       "<td>0.9638554</td>\n",
       "<td>124.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.4332953</td>\n",
       "<td>0.9661836</td>\n",
       "<td>124.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5733132</td>\n",
       "<td>0.9692029</td>\n",
       "<td>106.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4332953</td>\n",
       "<td>0.9703947</td>\n",
       "<td>124.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9792875</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.3123540</td>\n",
       "<td>1.0</td>\n",
       "<td>146.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9792875</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4332953</td>\n",
       "<td>0.9388082</td>\n",
       "<td>124.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4332953</td>\n",
       "<td>0.9677419</td>\n",
       "<td>124.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4332953</td>\n",
       "<td>0.9699821</td>\n",
       "<td>124.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.433295     0.963855  124\n",
       "max f2                       0.433295     0.966184  124\n",
       "max f0point5                 0.573313     0.969203  106\n",
       "max accuracy                 0.433295     0.970395  124\n",
       "max precision                0.979287     1         0\n",
       "max recall                   0.312354     1         146\n",
       "max specificity              0.979287     1         0\n",
       "max absolute_mcc             0.433295     0.938808  124\n",
       "max min_per_class_accuracy   0.433295     0.967742  124\n",
       "max mean_per_class_accuracy  0.433295     0.969982  124"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 40.79 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0131579</td>\n",
       "<td>0.9628819</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0322581</td>\n",
       "<td>0.0322581</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0230263</td>\n",
       "<td>0.9533590</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0241935</td>\n",
       "<td>0.0564516</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0328947</td>\n",
       "<td>0.9502933</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0241935</td>\n",
       "<td>0.0806452</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0427632</td>\n",
       "<td>0.9432361</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0241935</td>\n",
       "<td>0.1048387</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0526316</td>\n",
       "<td>0.9418574</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0241935</td>\n",
       "<td>0.1290323</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1019737</td>\n",
       "<td>0.9158052</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1209677</td>\n",
       "<td>0.25</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1513158</td>\n",
       "<td>0.8692245</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1209677</td>\n",
       "<td>0.3709677</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2006579</td>\n",
       "<td>0.8105281</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1209677</td>\n",
       "<td>0.4919355</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2993421</td>\n",
       "<td>0.7075336</td>\n",
       "<td>2.4516129</td>\n",
       "<td>2.4516129</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2419355</td>\n",
       "<td>0.7338710</td>\n",
       "<td>145.1612903</td>\n",
       "<td>145.1612903</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4013158</td>\n",
       "<td>0.4559975</td>\n",
       "<td>2.1352758</td>\n",
       "<td>2.3712322</td>\n",
       "<td>0.8709677</td>\n",
       "<td>0.9672131</td>\n",
       "<td>0.2177419</td>\n",
       "<td>0.9516129</td>\n",
       "<td>113.5275754</td>\n",
       "<td>137.1232152</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.2705564</td>\n",
       "<td>0.4903226</td>\n",
       "<td>2.0</td>\n",
       "<td>0.2</td>\n",
       "<td>0.8157895</td>\n",
       "<td>0.0483871</td>\n",
       "<td>1.0</td>\n",
       "<td>-50.9677419</td>\n",
       "<td>100.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5986842</td>\n",
       "<td>0.1836534</td>\n",
       "<td>0.0</td>\n",
       "<td>1.6703297</td>\n",
       "<td>0.0</td>\n",
       "<td>0.6813187</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>67.0329670</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7006579</td>\n",
       "<td>0.1322374</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4272300</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5821596</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.7230047</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7993421</td>\n",
       "<td>0.0793147</td>\n",
       "<td>0.0</td>\n",
       "<td>1.2510288</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5102881</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.1028807</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8980263</td>\n",
       "<td>0.0448171</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1135531</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4542125</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.3553114</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0079513</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4078947</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0131579                   0.962882           2.45161   2.45161            1                1                           0.0322581       0.0322581                  145.161   145.161\n",
       "    2        0.0230263                   0.953359           2.45161   2.45161            1                1                           0.0241935       0.0564516                  145.161   145.161\n",
       "    3        0.0328947                   0.950293           2.45161   2.45161            1                1                           0.0241935       0.0806452                  145.161   145.161\n",
       "    4        0.0427632                   0.943236           2.45161   2.45161            1                1                           0.0241935       0.104839                   145.161   145.161\n",
       "    5        0.0526316                   0.941857           2.45161   2.45161            1                1                           0.0241935       0.129032                   145.161   145.161\n",
       "    6        0.101974                    0.915805           2.45161   2.45161            1                1                           0.120968        0.25                       145.161   145.161\n",
       "    7        0.151316                    0.869225           2.45161   2.45161            1                1                           0.120968        0.370968                   145.161   145.161\n",
       "    8        0.200658                    0.810528           2.45161   2.45161            1                1                           0.120968        0.491935                   145.161   145.161\n",
       "    9        0.299342                    0.707534           2.45161   2.45161            1                1                           0.241935        0.733871                   145.161   145.161\n",
       "    10       0.401316                    0.455998           2.13528   2.37123            0.870968         0.967213                    0.217742        0.951613                   113.528   137.123\n",
       "    11       0.5                         0.270556           0.490323  2                  0.2              0.815789                    0.0483871       1                          -50.9677  100\n",
       "    12       0.598684                    0.183653           0         1.67033            0                0.681319                    0               1                          -100      67.033\n",
       "    13       0.700658                    0.132237           0         1.42723            0                0.58216                     0               1                          -100      42.723\n",
       "    14       0.799342                    0.0793147          0         1.25103            0                0.510288                    0               1                          -100      25.1029\n",
       "    15       0.898026                    0.0448171          0         1.11355            0                0.454212                    0               1                          -100      11.3553\n",
       "    16       1                           0.00795132         0         1                  0                0.407895                    0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.152755729065\n",
      "RMSE: 0.390839774159\n",
      "LogLoss: 0.481813619133\n",
      "Mean Per-Class Error: 0.196923076923\n",
      "AUC: 0.809230769231\n",
      "Gini: 0.618461538462\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.420686001908: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>19.0</td>\n",
       "<td>6.0</td>\n",
       "<td>0.24</td>\n",
       "<td> (6.0/25.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>2.0</td>\n",
       "<td>11.0</td>\n",
       "<td>0.1538</td>\n",
       "<td> (2.0/13.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>21.0</td>\n",
       "<td>17.0</td>\n",
       "<td>0.2105</td>\n",
       "<td> (8.0/38.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ----------\n",
       "0      19   6    0.24     (6.0/25.0)\n",
       "1      2    11   0.1538   (2.0/13.0)\n",
       "Total  21   17   0.2105   (8.0/38.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.4206860</td>\n",
       "<td>0.7333333</td>\n",
       "<td>16.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.4206860</td>\n",
       "<td>0.7971014</td>\n",
       "<td>16.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.6842872</td>\n",
       "<td>0.8108108</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.6842872</td>\n",
       "<td>0.8157895</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9709371</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0246933</td>\n",
       "<td>1.0</td>\n",
       "<td>36.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9709371</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.6842872</td>\n",
       "<td>0.6004806</td>\n",
       "<td>5.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4559573</td>\n",
       "<td>0.7692308</td>\n",
       "<td>14.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4206860</td>\n",
       "<td>0.8030769</td>\n",
       "<td>16.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.420686     0.733333  16\n",
       "max f2                       0.420686     0.797101  16\n",
       "max f0point5                 0.684287     0.810811  5\n",
       "max accuracy                 0.684287     0.815789  5\n",
       "max precision                0.970937     1         0\n",
       "max recall                   0.0246933    1         36\n",
       "max specificity              0.970937     1         0\n",
       "max absolute_mcc             0.684287     0.600481  5\n",
       "max min_per_class_accuracy   0.455957     0.769231  14\n",
       "max mean_per_class_accuracy  0.420686     0.803077  16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 34.21 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0263158</td>\n",
       "<td>0.9671841</td>\n",
       "<td>2.9230769</td>\n",
       "<td>2.9230769</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.0769231</td>\n",
       "<td>192.3076923</td>\n",
       "<td>192.3076923</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0263158</td>\n",
       "<td>0.9634310</td>\n",
       "<td>0.0</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.0769231</td>\n",
       "<td>-100.0</td>\n",
       "<td>192.3076923</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0526316</td>\n",
       "<td>0.9515437</td>\n",
       "<td>2.9230769</td>\n",
       "<td>2.9230769</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.1538462</td>\n",
       "<td>192.3076923</td>\n",
       "<td>192.3076923</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0526316</td>\n",
       "<td>0.9204302</td>\n",
       "<td>0.0</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1538462</td>\n",
       "<td>-100.0</td>\n",
       "<td>192.3076923</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0526316</td>\n",
       "<td>0.8893168</td>\n",
       "<td>0.0</td>\n",
       "<td>2.9230769</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.1538462</td>\n",
       "<td>-100.0</td>\n",
       "<td>192.3076923</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1052632</td>\n",
       "<td>0.7978554</td>\n",
       "<td>2.9230769</td>\n",
       "<td>2.9230769</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1538462</td>\n",
       "<td>0.3076923</td>\n",
       "<td>192.3076923</td>\n",
       "<td>192.3076923</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1578947</td>\n",
       "<td>0.6665591</td>\n",
       "<td>2.9230769</td>\n",
       "<td>2.9230769</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1538462</td>\n",
       "<td>0.4615385</td>\n",
       "<td>192.3076923</td>\n",
       "<td>192.3076923</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2105263</td>\n",
       "<td>0.6062020</td>\n",
       "<td>0.0</td>\n",
       "<td>2.1923077</td>\n",
       "<td>0.0</td>\n",
       "<td>0.75</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4615385</td>\n",
       "<td>-100.0</td>\n",
       "<td>119.2307692</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3157895</td>\n",
       "<td>0.4972917</td>\n",
       "<td>0.7307692</td>\n",
       "<td>1.7051282</td>\n",
       "<td>0.25</td>\n",
       "<td>0.5833333</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.5384615</td>\n",
       "<td>-26.9230769</td>\n",
       "<td>70.5128205</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3947368</td>\n",
       "<td>0.4406607</td>\n",
       "<td>2.9230769</td>\n",
       "<td>1.9487179</td>\n",
       "<td>1.0</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.2307692</td>\n",
       "<td>0.7692308</td>\n",
       "<td>192.3076923</td>\n",
       "<td>94.8717949</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.3210774</td>\n",
       "<td>0.7307692</td>\n",
       "<td>1.6923077</td>\n",
       "<td>0.25</td>\n",
       "<td>0.5789474</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.8461538</td>\n",
       "<td>-26.9230769</td>\n",
       "<td>69.2307692</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6052632</td>\n",
       "<td>0.1387541</td>\n",
       "<td>0.0</td>\n",
       "<td>1.3979933</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4782609</td>\n",
       "<td>0.0</td>\n",
       "<td>0.8461538</td>\n",
       "<td>-100.0</td>\n",
       "<td>39.7993311</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6842105</td>\n",
       "<td>0.0647476</td>\n",
       "<td>0.9743590</td>\n",
       "<td>1.3491124</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.4615385</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.9230769</td>\n",
       "<td>-2.5641026</td>\n",
       "<td>34.9112426</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7894737</td>\n",
       "<td>0.0540283</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1692308</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9230769</td>\n",
       "<td>-100.0</td>\n",
       "<td>16.9230769</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8947368</td>\n",
       "<td>0.0368757</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0316742</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3529412</td>\n",
       "<td>0.0</td>\n",
       "<td>0.9230769</td>\n",
       "<td>-100.0</td>\n",
       "<td>3.1674208</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0090053</td>\n",
       "<td>0.7307692</td>\n",
       "<td>1.0</td>\n",
       "<td>0.25</td>\n",
       "<td>0.3421053</td>\n",
       "<td>0.0769231</td>\n",
       "<td>1.0</td>\n",
       "<td>-26.9230769</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0263158                   0.967184           2.92308   2.92308            1                1                           0.0769231       0.0769231                  192.308   192.308\n",
       "    2        0.0263158                   0.963431           0         2.92308            0                1                           0               0.0769231                  -100      192.308\n",
       "    3        0.0526316                   0.951544           2.92308   2.92308            1                1                           0.0769231       0.153846                   192.308   192.308\n",
       "    4        0.0526316                   0.92043            0         2.92308            0                1                           0               0.153846                   -100      192.308\n",
       "    5        0.0526316                   0.889317           0         2.92308            0                1                           0               0.153846                   -100      192.308\n",
       "    6        0.105263                    0.797855           2.92308   2.92308            1                1                           0.153846        0.307692                   192.308   192.308\n",
       "    7        0.157895                    0.666559           2.92308   2.92308            1                1                           0.153846        0.461538                   192.308   192.308\n",
       "    8        0.210526                    0.606202           0         2.19231            0                0.75                        0               0.461538                   -100      119.231\n",
       "    9        0.315789                    0.497292           0.730769  1.70513            0.25             0.583333                    0.0769231       0.538462                   -26.9231  70.5128\n",
       "    10       0.394737                    0.440661           2.92308   1.94872            1                0.666667                    0.230769        0.769231                   192.308   94.8718\n",
       "    11       0.5                         0.321077           0.730769  1.69231            0.25             0.578947                    0.0769231       0.846154                   -26.9231  69.2308\n",
       "    12       0.605263                    0.138754           0         1.39799            0                0.478261                    0               0.846154                   -100      39.7993\n",
       "    13       0.684211                    0.0647476          0.974359  1.34911            0.333333         0.461538                    0.0769231       0.923077                   -2.5641   34.9112\n",
       "    14       0.789474                    0.0540283          0         1.16923            0                0.4                         0               0.923077                   -100      16.9231\n",
       "    15       0.894737                    0.0368757          0         1.03167            0                0.352941                    0               0.923077                   -100      3.16742\n",
       "    16       1                           0.00900531         0.730769  1                  0.25             0.342105                    0.0769231       1                          -26.9231  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>GLEASON</td>\n",
       "<td>73.4897232</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2549634</td></tr>\n",
       "<tr><td>PSA</td>\n",
       "<td>63.4471703</td>\n",
       "<td>0.8633475</td>\n",
       "<td>0.2201221</td></tr>\n",
       "<tr><td>ID</td>\n",
       "<td>57.4138336</td>\n",
       "<td>0.7812498</td>\n",
       "<td>0.1991901</td></tr>\n",
       "<tr><td>VOL</td>\n",
       "<td>50.6388054</td>\n",
       "<td>0.6890597</td>\n",
       "<td>0.1756850</td></tr>\n",
       "<tr><td>DPROS</td>\n",
       "<td>24.5224018</td>\n",
       "<td>0.3336848</td>\n",
       "<td>0.0850774</td></tr>\n",
       "<tr><td>AGE</td>\n",
       "<td>15.4116030</td>\n",
       "<td>0.2097110</td>\n",
       "<td>0.0534686</td></tr>\n",
       "<tr><td>DCAPS</td>\n",
       "<td>3.1581650</td>\n",
       "<td>0.0429742</td>\n",
       "<td>0.0109569</td></tr>\n",
       "<tr><td>RACE</td>\n",
       "<td>0.1546198</td>\n",
       "<td>0.0021040</td>\n",
       "<td>0.0005364</td></tr></table></div>"
      ],
      "text/plain": [
       "variable    relative_importance    scaled_importance    percentage\n",
       "----------  ---------------------  -------------------  ------------\n",
       "GLEASON     73.4897                1                    0.254963\n",
       "PSA         63.4472                0.863348             0.220122\n",
       "ID          57.4138                0.78125              0.19919\n",
       "VOL         50.6388                0.68906              0.175685\n",
       "DPROS       24.5224                0.333685             0.0850774\n",
       "AGE         15.4116                0.209711             0.0534686\n",
       "DCAPS       3.15816                0.0429742            0.0109569\n",
       "RACE        0.15462                0.00210397           0.000536434"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{u'__meta': {u'schema_name': u'GBMModelV3',\n",
       "  u'schema_type': u'GBMModel',\n",
       "  u'schema_version': 3},\n",
       " u'algo': u'gbm',\n",
       " u'algo_full_name': u'Gradient Boosting Machine',\n",
       " u'compatible_frames': None,\n",
       " u'data_frame': {u'URL': u'/3/Frames/py_25_sid_8795',\n",
       "  u'__meta': {u'schema_name': u'FrameKeyV3',\n",
       "   u'schema_type': u'Key<Frame>',\n",
       "   u'schema_version': 3},\n",
       "  u'name': u'py_25_sid_8795',\n",
       "  u'type': u'Key<Frame>'},\n",
       " u'model_id': {u'URL': u'/3/Models/glm_model_with_training_and_validtion_python',\n",
       "  u'__meta': {u'schema_name': u'ModelKeyV3',\n",
       "   u'schema_type': u'Key<Model>',\n",
       "   u'schema_version': 3},\n",
       "  u'name': u'glm_model_with_training_and_validtion_python',\n",
       "  u'type': u'Key<Model>'},\n",
       " u'output': {u'__meta': {u'schema_name': u'GBMModelOutputV3',\n",
       "   u'schema_type': u'GBMOutput',\n",
       "   u'schema_version': 3},\n",
       "  u'cross_validation_fold_assignment_frame_id': None,\n",
       "  u'cross_validation_holdout_predictions_frame_id': None,\n",
       "  u'cross_validation_metrics': None,\n",
       "  u'cross_validation_metrics_summary': None,\n",
       "  u'cross_validation_models': None,\n",
       "  u'cross_validation_predictions': None,\n",
       "  u'domains': [None, None, None, None, None, None, None, None, [u'0', u'1']],\n",
       "  u'end_time': 1510640872969,\n",
       "  u'help': {u'__meta': u'Metadata on this schema instance, to make it self-describing.',\n",
       "   u'cross_validation_fold_assignment_frame_id': u'Cross-validation fold assignment (each row is assigned to one holdout fold)',\n",
       "   u'cross_validation_holdout_predictions_frame_id': u'Cross-validation holdout predictions (full out-of-sample predictions on training data)',\n",
       "   u'cross_validation_metrics': u'Cross-validation model metrics',\n",
       "   u'cross_validation_metrics_summary': u'Cross-validation model metrics summary',\n",
       "   u'cross_validation_models': u'Cross-validation models (model ids)',\n",
       "   u'cross_validation_predictions': u'Cross-validation predictions, one per cv model (deprecated, use cross_validation_holdout_predictions_frame_id instead)',\n",
       "   u'domains': u'Domains for categorical columns',\n",
       "   u'end_time': u'End time in milliseconds',\n",
       "   u'help': u'Help information for output fields',\n",
       "   u'init_f': u'The Intercept term, the initial model function value to which trees make adjustments',\n",
       "   u'model_category': u'Category of the model (e.g., Binomial)',\n",
       "   u'model_summary': u'Model summary',\n",
       "   u'names': u'Column names',\n",
       "   u'run_time': u'Runtime in milliseconds',\n",
       "   u'scoring_history': u'Scoring history',\n",
       "   u'start_time': u'Start time in milliseconds',\n",
       "   u'status': u'Job status',\n",
       "   u'training_metrics': u'Training data model metrics',\n",
       "   u'validation_metrics': u'Validation data model metrics',\n",
       "   u'variable_importances': u'Variable Importances'},\n",
       "  u'init_f': -0.3726752852851735,\n",
       "  u'model_category': u'Binomial',\n",
       "  u'model_summary': ,\n",
       "  u'names': [u'ID',\n",
       "   u'AGE',\n",
       "   u'RACE',\n",
       "   u'DPROS',\n",
       "   u'DCAPS',\n",
       "   u'PSA',\n",
       "   u'VOL',\n",
       "   u'GLEASON',\n",
       "   u'CAPSULE'],\n",
       "  u'run_time': 256,\n",
       "  u'scoring_history': ,\n",
       "  u'start_time': 1510640872713,\n",
       "  u'status': None,\n",
       "  u'training_metrics': ,\n",
       "  u'validation_metrics': ,\n",
       "  u'variable_importances': },\n",
       " u'parameters': [{u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': {u'URL': u'/3/Models/glm_model_with_training_and_validtion_python',\n",
       "    u'__meta': {u'schema_name': u'ModelKeyV3',\n",
       "     u'schema_type': u'Key<Model>',\n",
       "     u'schema_version': 3},\n",
       "    u'name': u'glm_model_with_training_and_validtion_python',\n",
       "    u'type': u'Key<Model>'},\n",
       "   u'default_value': None,\n",
       "   u'gridable': False,\n",
       "   u'help': u'Destination id for this model; auto-generated if not specified.',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'model_id',\n",
       "   u'level': u'critical',\n",
       "   u'name': u'model_id',\n",
       "   u'required': False,\n",
       "   u'type': u'Key<Model>',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': {u'URL': u'/3/Frames/py_25_sid_8795',\n",
       "    u'__meta': {u'schema_name': u'FrameKeyV3',\n",
       "     u'schema_type': u'Key<Frame>',\n",
       "     u'schema_version': 3},\n",
       "    u'name': u'py_25_sid_8795',\n",
       "    u'type': u'Key<Frame>'},\n",
       "   u'default_value': None,\n",
       "   u'gridable': False,\n",
       "   u'help': u'Id of the training data frame (Not required, to allow initial validation of model parameters).',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'training_frame',\n",
       "   u'level': u'critical',\n",
       "   u'name': u'training_frame',\n",
       "   u'required': False,\n",
       "   u'type': u'Key<Frame>',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': {u'URL': u'/3/Frames/py_26_sid_8795',\n",
       "    u'__meta': {u'schema_name': u'FrameKeyV3',\n",
       "     u'schema_type': u'Key<Frame>',\n",
       "     u'schema_version': 3},\n",
       "    u'name': u'py_26_sid_8795',\n",
       "    u'type': u'Key<Frame>'},\n",
       "   u'default_value': None,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Id of the validation data frame.',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'validation_frame',\n",
       "   u'level': u'critical',\n",
       "   u'name': u'validation_frame',\n",
       "   u'required': False,\n",
       "   u'type': u'Key<Frame>',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 0,\n",
       "   u'default_value': 0,\n",
       "   u'gridable': False,\n",
       "   u'help': u'Number of folds for N-fold cross-validation (0 to disable or >= 2).',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'nfolds',\n",
       "   u'level': u'critical',\n",
       "   u'name': u'nfolds',\n",
       "   u'required': False,\n",
       "   u'type': u'int',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': False,\n",
       "   u'default_value': False,\n",
       "   u'gridable': False,\n",
       "   u'help': u'Whether to keep the predictions of the cross-validation models.',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'keep_cross_validation_predictions',\n",
       "   u'level': u'expert',\n",
       "   u'name': u'keep_cross_validation_predictions',\n",
       "   u'required': False,\n",
       "   u'type': u'boolean',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': False,\n",
       "   u'default_value': False,\n",
       "   u'gridable': False,\n",
       "   u'help': u'Whether to keep the cross-validation fold assignment.',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'keep_cross_validation_fold_assignment',\n",
       "   u'level': u'expert',\n",
       "   u'name': u'keep_cross_validation_fold_assignment',\n",
       "   u'required': False,\n",
       "   u'type': u'boolean',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': False,\n",
       "   u'default_value': False,\n",
       "   u'gridable': False,\n",
       "   u'help': u'Whether to score during each iteration of model training.',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'score_each_iteration',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'score_each_iteration',\n",
       "   u'required': False,\n",
       "   u'type': u'boolean',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 0,\n",
       "   u'default_value': 0,\n",
       "   u'gridable': False,\n",
       "   u'help': u'Score the model after every so many trees. Disabled if set to 0.',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'score_tree_interval',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'score_tree_interval',\n",
       "   u'required': False,\n",
       "   u'type': u'int',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': u'AUTO',\n",
       "   u'default_value': u'AUTO',\n",
       "   u'gridable': True,\n",
       "   u'help': u\"Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will stratify the folds based on the response variable, for classification problems.\",\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'fold_assignment',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'fold_assignment',\n",
       "   u'required': False,\n",
       "   u'type': u'enum',\n",
       "   u'values': [u'AUTO', u'Random', u'Modulo', u'Stratified']},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': None,\n",
       "   u'default_value': None,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Column with cross-validation fold index assignment per observation.',\n",
       "   u'is_member_of_frames': [u'training_frame'],\n",
       "   u'is_mutually_exclusive_with': [u'response_column',\n",
       "    u'weights_column',\n",
       "    u'ignored_columns',\n",
       "    u'offset_column'],\n",
       "   u'label': u'fold_column',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'fold_column',\n",
       "   u'required': False,\n",
       "   u'type': u'VecSpecifier',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': {u'__meta': {u'schema_name': u'ColSpecifierV3',\n",
       "     u'schema_type': u'VecSpecifier',\n",
       "     u'schema_version': 3},\n",
       "    u'column_name': u'CAPSULE',\n",
       "    u'is_member_of_frames': None},\n",
       "   u'default_value': None,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Response variable column.',\n",
       "   u'is_member_of_frames': [u'training_frame', u'validation_frame'],\n",
       "   u'is_mutually_exclusive_with': [u'weights_column',\n",
       "    u'ignored_columns',\n",
       "    u'offset_column',\n",
       "    u'fold_column'],\n",
       "   u'label': u'response_column',\n",
       "   u'level': u'critical',\n",
       "   u'name': u'response_column',\n",
       "   u'required': False,\n",
       "   u'type': u'VecSpecifier',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': None,\n",
       "   u'default_value': None,\n",
       "   u'gridable': False,\n",
       "   u'help': u'Names of columns to ignore for training.',\n",
       "   u'is_member_of_frames': [u'training_frame', u'validation_frame'],\n",
       "   u'is_mutually_exclusive_with': [u'response_column',\n",
       "    u'weights_column',\n",
       "    u'offset_column',\n",
       "    u'fold_column'],\n",
       "   u'label': u'ignored_columns',\n",
       "   u'level': u'critical',\n",
       "   u'name': u'ignored_columns',\n",
       "   u'required': False,\n",
       "   u'type': u'string[]',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': True,\n",
       "   u'default_value': True,\n",
       "   u'gridable': False,\n",
       "   u'help': u'Ignore constant columns.',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'ignore_const_cols',\n",
       "   u'level': u'critical',\n",
       "   u'name': u'ignore_const_cols',\n",
       "   u'required': False,\n",
       "   u'type': u'boolean',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': None,\n",
       "   u'default_value': None,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Offset column. This will be added to the combination of columns before applying the link function.',\n",
       "   u'is_member_of_frames': [u'training_frame', u'validation_frame'],\n",
       "   u'is_mutually_exclusive_with': [u'response_column',\n",
       "    u'weights_column',\n",
       "    u'ignored_columns',\n",
       "    u'fold_column'],\n",
       "   u'label': u'offset_column',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'offset_column',\n",
       "   u'required': False,\n",
       "   u'type': u'VecSpecifier',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': None,\n",
       "   u'default_value': None,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from the dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative weights are not allowed.',\n",
       "   u'is_member_of_frames': [u'training_frame', u'validation_frame'],\n",
       "   u'is_mutually_exclusive_with': [u'response_column',\n",
       "    u'ignored_columns',\n",
       "    u'offset_column',\n",
       "    u'fold_column'],\n",
       "   u'label': u'weights_column',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'weights_column',\n",
       "   u'required': False,\n",
       "   u'type': u'VecSpecifier',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': False,\n",
       "   u'default_value': False,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Balance training data class counts via over/under-sampling (for imbalanced data).',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'balance_classes',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'balance_classes',\n",
       "   u'required': False,\n",
       "   u'type': u'boolean',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': None,\n",
       "   u'default_value': None,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will be automatically computed to obtain class balance during training. Requires balance_classes.',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'class_sampling_factors',\n",
       "   u'level': u'expert',\n",
       "   u'name': u'class_sampling_factors',\n",
       "   u'required': False,\n",
       "   u'type': u'float[]',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 5.0,\n",
       "   u'default_value': 5.0,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires balance_classes.',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'max_after_balance_size',\n",
       "   u'level': u'expert',\n",
       "   u'name': u'max_after_balance_size',\n",
       "   u'required': False,\n",
       "   u'type': u'float',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 20,\n",
       "   u'default_value': 20,\n",
       "   u'gridable': False,\n",
       "   u'help': u'[Deprecated] Maximum size (# classes) for confusion matrices to be printed in the Logs',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'max_confusion_matrix_size',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'max_confusion_matrix_size',\n",
       "   u'required': False,\n",
       "   u'type': u'int',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 0,\n",
       "   u'default_value': 0,\n",
       "   u'gridable': False,\n",
       "   u'help': u'Max. number (top K) of predictions to use for hit ratio computation (for multi-class only, 0 to disable)',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'max_hit_ratio_k',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'max_hit_ratio_k',\n",
       "   u'required': False,\n",
       "   u'type': u'int',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 50,\n",
       "   u'default_value': 50,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Number of trees.',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'ntrees',\n",
       "   u'level': u'critical',\n",
       "   u'name': u'ntrees',\n",
       "   u'required': False,\n",
       "   u'type': u'int',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 5,\n",
       "   u'default_value': 5,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Maximum tree depth.',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'max_depth',\n",
       "   u'level': u'critical',\n",
       "   u'name': u'max_depth',\n",
       "   u'required': False,\n",
       "   u'type': u'int',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 10.0,\n",
       "   u'default_value': 10.0,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Fewest allowed (weighted) observations in a leaf.',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'min_rows',\n",
       "   u'level': u'critical',\n",
       "   u'name': u'min_rows',\n",
       "   u'required': False,\n",
       "   u'type': u'double',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 20,\n",
       "   u'default_value': 20,\n",
       "   u'gridable': True,\n",
       "   u'help': u'For numerical columns (real/int), build a histogram of (at least) this many bins, then split at the best point',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'nbins',\n",
       "   u'level': u'critical',\n",
       "   u'name': u'nbins',\n",
       "   u'required': False,\n",
       "   u'type': u'int',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 1024,\n",
       "   u'default_value': 1024,\n",
       "   u'gridable': True,\n",
       "   u'help': u'For numerical columns (real/int), build a histogram of (at most) this many bins at the root level, then decrease by factor of two per level',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'nbins_top_level',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'nbins_top_level',\n",
       "   u'required': False,\n",
       "   u'type': u'int',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 1024,\n",
       "   u'default_value': 1024,\n",
       "   u'gridable': True,\n",
       "   u'help': u'For categorical columns (factors), build a histogram of this many bins, then split at the best point. Higher values can lead to more overfitting.',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'nbins_cats',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'nbins_cats',\n",
       "   u'required': False,\n",
       "   u'type': u'int',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 1.7976931348623157e+308,\n",
       "   u'default_value': 1.7976931348623157e+308,\n",
       "   u'gridable': True,\n",
       "   u'help': u'r2_stopping is no longer supported and will be ignored if set - please use stopping_rounds, stopping_metric and stopping_tolerance instead. Previous version of H2O would stop making trees when the R^2 metric equals or exceeds this',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'r2_stopping',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'r2_stopping',\n",
       "   u'required': False,\n",
       "   u'type': u'double',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 0,\n",
       "   u'default_value': 0,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Early stopping based on convergence of stopping_metric. Stop if simple moving average of length k of the stopping_metric does not improve for k:=stopping_rounds scoring events (0 to disable)',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'stopping_rounds',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'stopping_rounds',\n",
       "   u'required': False,\n",
       "   u'type': u'int',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': u'AUTO',\n",
       "   u'default_value': u'AUTO',\n",
       "   u'gridable': True,\n",
       "   u'help': u'Metric to use for early stopping (AUTO: logloss for classification, deviance for regression)',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'stopping_metric',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'stopping_metric',\n",
       "   u'required': False,\n",
       "   u'type': u'enum',\n",
       "   u'values': [u'AUTO',\n",
       "    u'deviance',\n",
       "    u'logloss',\n",
       "    u'MSE',\n",
       "    u'RMSE',\n",
       "    u'MAE',\n",
       "    u'RMSLE',\n",
       "    u'AUC',\n",
       "    u'lift_top_group',\n",
       "    u'misclassification',\n",
       "    u'mean_per_class_error']},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 0.001,\n",
       "   u'default_value': 0.001,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Relative tolerance for metric-based stopping criterion (stop if relative improvement is not at least this much)',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'stopping_tolerance',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'stopping_tolerance',\n",
       "   u'required': False,\n",
       "   u'type': u'double',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 0.0,\n",
       "   u'default_value': 0.0,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Maximum allowed runtime in seconds for model training. Use 0 to disable.',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'max_runtime_secs',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'max_runtime_secs',\n",
       "   u'required': False,\n",
       "   u'type': u'double',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 8950247841618986588,\n",
       "   u'default_value': -1,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Seed for pseudo random number generator (if applicable)',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'seed',\n",
       "   u'level': u'critical',\n",
       "   u'name': u'seed',\n",
       "   u'required': False,\n",
       "   u'type': u'long',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': False,\n",
       "   u'default_value': False,\n",
       "   u'gridable': False,\n",
       "   u'help': u'Run on one node only; no network overhead but fewer cpus used.  Suitable for small datasets.',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'build_tree_one_node',\n",
       "   u'level': u'expert',\n",
       "   u'name': u'build_tree_one_node',\n",
       "   u'required': False,\n",
       "   u'type': u'boolean',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 0.1,\n",
       "   u'default_value': 0.1,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Learning rate (from 0.0 to 1.0)',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'learn_rate',\n",
       "   u'level': u'critical',\n",
       "   u'name': u'learn_rate',\n",
       "   u'required': False,\n",
       "   u'type': u'double',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 1.0,\n",
       "   u'default_value': 1.0,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Scale the learning rate by this factor after each tree (e.g., 0.99 or 0.999) ',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'learn_rate_annealing',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'learn_rate_annealing',\n",
       "   u'required': False,\n",
       "   u'type': u'double',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': u'bernoulli',\n",
       "   u'default_value': u'AUTO',\n",
       "   u'gridable': True,\n",
       "   u'help': u'Distribution function',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'distribution',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'distribution',\n",
       "   u'required': False,\n",
       "   u'type': u'enum',\n",
       "   u'values': [u'AUTO',\n",
       "    u'bernoulli',\n",
       "    u'multinomial',\n",
       "    u'gaussian',\n",
       "    u'poisson',\n",
       "    u'gamma',\n",
       "    u'tweedie',\n",
       "    u'laplace',\n",
       "    u'quantile',\n",
       "    u'huber']},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 0.5,\n",
       "   u'default_value': 0.5,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Desired quantile for Quantile regression, must be between 0 and 1.',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'quantile_alpha',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'quantile_alpha',\n",
       "   u'required': False,\n",
       "   u'type': u'double',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 1.5,\n",
       "   u'default_value': 1.5,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Tweedie power for Tweedie regression, must be between 1 and 2.',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'tweedie_power',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'tweedie_power',\n",
       "   u'required': False,\n",
       "   u'type': u'double',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 0.9,\n",
       "   u'default_value': 0.9,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Desired quantile for Huber/M-regression (threshold between quadratic and linear loss, must be between 0 and 1).',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'huber_alpha',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'huber_alpha',\n",
       "   u'required': False,\n",
       "   u'type': u'double',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': None,\n",
       "   u'default_value': None,\n",
       "   u'gridable': False,\n",
       "   u'help': u'Model checkpoint to resume training with.',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'checkpoint',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'checkpoint',\n",
       "   u'required': False,\n",
       "   u'type': u'Key<Model>',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 1.0,\n",
       "   u'default_value': 1.0,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Row sample rate per tree (from 0.0 to 1.0)',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'sample_rate',\n",
       "   u'level': u'critical',\n",
       "   u'name': u'sample_rate',\n",
       "   u'required': False,\n",
       "   u'type': u'double',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': None,\n",
       "   u'default_value': None,\n",
       "   u'gridable': True,\n",
       "   u'help': u'A list of row sample rates per class (relative fraction for each class, from 0.0 to 1.0), for each tree',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'sample_rate_per_class',\n",
       "   u'level': u'expert',\n",
       "   u'name': u'sample_rate_per_class',\n",
       "   u'required': False,\n",
       "   u'type': u'double[]',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 1.0,\n",
       "   u'default_value': 1.0,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Column sample rate (from 0.0 to 1.0)',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'col_sample_rate',\n",
       "   u'level': u'critical',\n",
       "   u'name': u'col_sample_rate',\n",
       "   u'required': False,\n",
       "   u'type': u'double',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 1.0,\n",
       "   u'default_value': 1.0,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Relative change of the column sampling rate for every level (from 0.0 to 2.0)',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'col_sample_rate_change_per_level',\n",
       "   u'level': u'expert',\n",
       "   u'name': u'col_sample_rate_change_per_level',\n",
       "   u'required': False,\n",
       "   u'type': u'double',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 1.0,\n",
       "   u'default_value': 1.0,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Column sample rate per tree (from 0.0 to 1.0)',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'col_sample_rate_per_tree',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'col_sample_rate_per_tree',\n",
       "   u'required': False,\n",
       "   u'type': u'double',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 1e-05,\n",
       "   u'default_value': 1e-05,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Minimum relative improvement in squared error reduction for a split to happen',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'min_split_improvement',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'min_split_improvement',\n",
       "   u'required': False,\n",
       "   u'type': u'double',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': u'AUTO',\n",
       "   u'default_value': u'AUTO',\n",
       "   u'gridable': True,\n",
       "   u'help': u'What type of histogram to use for finding optimal split points',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'histogram_type',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'histogram_type',\n",
       "   u'required': False,\n",
       "   u'type': u'enum',\n",
       "   u'values': [u'AUTO',\n",
       "    u'UniformAdaptive',\n",
       "    u'Random',\n",
       "    u'QuantilesGlobal',\n",
       "    u'RoundRobin']},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 1.7976931348623157e+308,\n",
       "   u'default_value': 1.7976931348623157e+308,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Maximum absolute value of a leaf node prediction',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'max_abs_leafnode_pred',\n",
       "   u'level': u'expert',\n",
       "   u'name': u'max_abs_leafnode_pred',\n",
       "   u'required': False,\n",
       "   u'type': u'double',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': 0.0,\n",
       "   u'default_value': 0.0,\n",
       "   u'gridable': True,\n",
       "   u'help': u'Bandwidth (sigma) of Gaussian multiplicative noise ~N(1,sigma) for tree node predictions',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'pred_noise_bandwidth',\n",
       "   u'level': u'expert',\n",
       "   u'name': u'pred_noise_bandwidth',\n",
       "   u'required': False,\n",
       "   u'type': u'double',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': u'AUTO',\n",
       "   u'default_value': u'AUTO',\n",
       "   u'gridable': True,\n",
       "   u'help': u'Encoding scheme for categorical features',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'categorical_encoding',\n",
       "   u'level': u'secondary',\n",
       "   u'name': u'categorical_encoding',\n",
       "   u'required': False,\n",
       "   u'type': u'enum',\n",
       "   u'values': [u'AUTO',\n",
       "    u'Enum',\n",
       "    u'OneHotInternal',\n",
       "    u'OneHotExplicit',\n",
       "    u'Binary',\n",
       "    u'Eigen',\n",
       "    u'LabelEncoder',\n",
       "    u'SortByResponse',\n",
       "    u'EnumLimited']},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': False,\n",
       "   u'default_value': False,\n",
       "   u'gridable': False,\n",
       "   u'help': u'Use Platt Scaling to calculate calibrated class probabilities. Calibration can provide more accurate estimates of class probabilities.',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'calibrate_model',\n",
       "   u'level': u'expert',\n",
       "   u'name': u'calibrate_model',\n",
       "   u'required': False,\n",
       "   u'type': u'boolean',\n",
       "   u'values': []},\n",
       "  {u'__meta': {u'schema_name': u'ModelParameterSchemaV3',\n",
       "    u'schema_type': u'Iced',\n",
       "    u'schema_version': 3},\n",
       "   u'actual_value': None,\n",
       "   u'default_value': None,\n",
       "   u'gridable': False,\n",
       "   u'help': u'Calibration frame for Platt Scaling',\n",
       "   u'is_member_of_frames': [],\n",
       "   u'is_mutually_exclusive_with': [],\n",
       "   u'label': u'calibration_frame',\n",
       "   u'level': u'expert',\n",
       "   u'name': u'calibration_frame',\n",
       "   u'required': False,\n",
       "   u'type': u'Key<Frame>',\n",
       "   u'values': []}],\n",
       " u'response_column_name': u'CAPSULE',\n",
       " u'timestamp': 0}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model_with_training_and_validtion._model_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'coefficients_table'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-55d32239c3bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgbm_model_with_training_and_validtion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coefficients_table'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m## GBM model does not have coefficients table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'coefficients_table'"
     ]
    }
   ],
   "source": [
    "gbm_model_with_training_and_validtion._model_json['output']['coefficients_table']\n",
    "## GBM model does not have coefficients table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'ID',\n",
       " u'AGE',\n",
       " u'RACE',\n",
       " u'DPROS',\n",
       " u'DCAPS',\n",
       " u'PSA',\n",
       " u'VOL',\n",
       " u'GLEASON',\n",
       " u'CAPSULE']"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model_with_training_and_validtion._model_json['output']['names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm_model_with_training_and_validtion._model_json['output']['cross_validation_predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{u'URL': u'/3/Frames/prediction_GBM_model_python_1510608322538_2496_cv_1',\n",
       "  u'__meta': {u'schema_name': u'FrameKeyV3',\n",
       "   u'schema_type': u'Key<Frame>',\n",
       "   u'schema_version': 3},\n",
       "  u'name': u'prediction_GBM_model_python_1510608322538_2496_cv_1',\n",
       "  u'type': u'Key<Frame>'},\n",
       " {u'URL': u'/3/Frames/prediction_GBM_model_python_1510608322538_2496_cv_2',\n",
       "  u'__meta': {u'schema_name': u'FrameKeyV3',\n",
       "   u'schema_type': u'Key<Frame>',\n",
       "   u'schema_version': 3},\n",
       "  u'name': u'prediction_GBM_model_python_1510608322538_2496_cv_2',\n",
       "  u'type': u'Key<Frame>'},\n",
       " {u'URL': u'/3/Frames/prediction_GBM_model_python_1510608322538_2496_cv_3',\n",
       "  u'__meta': {u'schema_name': u'FrameKeyV3',\n",
       "   u'schema_type': u'Key<Frame>',\n",
       "   u'schema_version': 3},\n",
       "  u'name': u'prediction_GBM_model_python_1510608322538_2496_cv_3',\n",
       "  u'type': u'Key<Frame>'},\n",
       " {u'URL': u'/3/Frames/prediction_GBM_model_python_1510608322538_2496_cv_4',\n",
       "  u'__meta': {u'schema_name': u'FrameKeyV3',\n",
       "   u'schema_type': u'Key<Frame>',\n",
       "   u'schema_version': 3},\n",
       "  u'name': u'prediction_GBM_model_python_1510608322538_2496_cv_4',\n",
       "  u'type': u'Key<Frame>'},\n",
       " {u'URL': u'/3/Frames/prediction_GBM_model_python_1510608322538_2496_cv_5',\n",
       "  u'__meta': {u'schema_name': u'FrameKeyV3',\n",
       "   u'schema_type': u'Key<Frame>',\n",
       "   u'schema_version': 3},\n",
       "  u'name': u'prediction_GBM_model_python_1510608322538_2496_cv_5',\n",
       "  u'type': u'Key<Frame>'}]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model_with_training_and_cv._model_json['output']['cross_validation_predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.0637863025683\n",
      "RMSE: 0.252559503025\n",
      "LogLoss: 0.244491796997\n",
      "Mean Per-Class Error: 0.0581900895454\n",
      "AUC: 0.98825256975\n",
      "Gini: 0.976505139501\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.369290229047: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>208.0</td>\n",
       "<td>19.0</td>\n",
       "<td>0.0837</td>\n",
       "<td> (19.0/227.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>5.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.0327</td>\n",
       "<td> (5.0/153.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>213.0</td>\n",
       "<td>167.0</td>\n",
       "<td>0.0632</td>\n",
       "<td> (24.0/380.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      208  19   0.0837   (19.0/227.0)\n",
       "1      5    148  0.0327   (5.0/153.0)\n",
       "Total  213  167  0.0632   (24.0/380.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3692902</td>\n",
       "<td>0.925</td>\n",
       "<td>166.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.3284870</td>\n",
       "<td>0.9554140</td>\n",
       "<td>172.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5709882</td>\n",
       "<td>0.9471366</td>\n",
       "<td>131.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4617671</td>\n",
       "<td>0.9368421</td>\n",
       "<td>150.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9740913</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.2716047</td>\n",
       "<td>1.0</td>\n",
       "<td>200.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9740913</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.3692902</td>\n",
       "<td>0.8731243</td>\n",
       "<td>166.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4303894</td>\n",
       "<td>0.9295154</td>\n",
       "<td>158.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.3692902</td>\n",
       "<td>0.9418099</td>\n",
       "<td>166.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.36929      0.925     166\n",
       "max f2                       0.328487     0.955414  172\n",
       "max f0point5                 0.570988     0.947137  131\n",
       "max accuracy                 0.461767     0.936842  150\n",
       "max precision                0.974091     1         0\n",
       "max recall                   0.271605     1         200\n",
       "max specificity              0.974091     1         0\n",
       "max absolute_mcc             0.36929      0.873124  166\n",
       "max min_per_class_accuracy   0.430389     0.929515  158\n",
       "max mean_per_class_accuracy  0.36929      0.94181   166"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 40.26 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0105263</td>\n",
       "<td>0.9656726</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0261438</td>\n",
       "<td>0.0261438</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0210526</td>\n",
       "<td>0.9589343</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0261438</td>\n",
       "<td>0.0522876</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0315789</td>\n",
       "<td>0.9507825</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0261438</td>\n",
       "<td>0.0784314</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0421053</td>\n",
       "<td>0.9422672</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0261438</td>\n",
       "<td>0.1045752</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.9301226</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0196078</td>\n",
       "<td>0.1241830</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.9044146</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1241830</td>\n",
       "<td>0.2483660</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.8446853</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1241830</td>\n",
       "<td>0.3725490</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.7961432</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1241830</td>\n",
       "<td>0.4967320</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.6723258</td>\n",
       "<td>2.4836601</td>\n",
       "<td>2.4836601</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2483660</td>\n",
       "<td>0.7450980</td>\n",
       "<td>148.3660131</td>\n",
       "<td>148.3660131</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.4587689</td>\n",
       "<td>1.6993464</td>\n",
       "<td>2.2875817</td>\n",
       "<td>0.6842105</td>\n",
       "<td>0.9210526</td>\n",
       "<td>0.1699346</td>\n",
       "<td>0.9150327</td>\n",
       "<td>69.9346405</td>\n",
       "<td>128.7581699</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.2941654</td>\n",
       "<td>0.7843137</td>\n",
       "<td>1.9869281</td>\n",
       "<td>0.3157895</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0784314</td>\n",
       "<td>0.9934641</td>\n",
       "<td>-21.5686275</td>\n",
       "<td>98.6928105</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.1936958</td>\n",
       "<td>0.0653595</td>\n",
       "<td>1.6666667</td>\n",
       "<td>0.0263158</td>\n",
       "<td>0.6710526</td>\n",
       "<td>0.0065359</td>\n",
       "<td>1.0</td>\n",
       "<td>-93.4640523</td>\n",
       "<td>66.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.1169011</td>\n",
       "<td>0.0</td>\n",
       "<td>1.4285714</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5751880</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>42.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0800475</td>\n",
       "<td>0.0</td>\n",
       "<td>1.25</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5032895</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>25.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0473553</td>\n",
       "<td>0.0</td>\n",
       "<td>1.1111111</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4473684</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>11.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0097484</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4026316</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0105263                   0.965673           2.48366    2.48366            1                1                           0.0261438       0.0261438                  148.366   148.366\n",
       "    2        0.0210526                   0.958934           2.48366    2.48366            1                1                           0.0261438       0.0522876                  148.366   148.366\n",
       "    3        0.0315789                   0.950783           2.48366    2.48366            1                1                           0.0261438       0.0784314                  148.366   148.366\n",
       "    4        0.0421053                   0.942267           2.48366    2.48366            1                1                           0.0261438       0.104575                   148.366   148.366\n",
       "    5        0.05                        0.930123           2.48366    2.48366            1                1                           0.0196078       0.124183                   148.366   148.366\n",
       "    6        0.1                         0.904415           2.48366    2.48366            1                1                           0.124183        0.248366                   148.366   148.366\n",
       "    7        0.15                        0.844685           2.48366    2.48366            1                1                           0.124183        0.372549                   148.366   148.366\n",
       "    8        0.2                         0.796143           2.48366    2.48366            1                1                           0.124183        0.496732                   148.366   148.366\n",
       "    9        0.3                         0.672326           2.48366    2.48366            1                1                           0.248366        0.745098                   148.366   148.366\n",
       "    10       0.4                         0.458769           1.69935    2.28758            0.684211         0.921053                    0.169935        0.915033                   69.9346   128.758\n",
       "    11       0.5                         0.294165           0.784314   1.98693            0.315789         0.8                         0.0784314       0.993464                   -21.5686  98.6928\n",
       "    12       0.6                         0.193696           0.0653595  1.66667            0.0263158        0.671053                    0.00653595      1                          -93.4641  66.6667\n",
       "    13       0.7                         0.116901           0          1.42857            0                0.575188                    0               1                          -100      42.8571\n",
       "    14       0.8                         0.0800475          0          1.25               0                0.503289                    0               1                          -100      25\n",
       "    15       0.9                         0.0473553          0          1.11111            0                0.447368                    0               1                          -100      11.1111\n",
       "    16       1                           0.00974841         0          1                  0                0.402632                    0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model_with_training_and_cv._model_json['output']['training_metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06378630256832155"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_model_with_training_and_cv._model_json['output']['training_metrics']['MSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbm_model_with_training_and_cv._model_json['output']['training_metrics']['R^2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#: Plotting GBM Model scoring plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEXCAYAAAC+mHPKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnjCcc85FxROGc865qHjCcM45F5X/Dw+Ih+O2QfBFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11be06250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbm_model_with_training_and_cv.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
